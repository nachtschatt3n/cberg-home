# IMPORTANT: This file is not tracked by flux and should never be. Its
# purpose is to only install the Flux components and CRDs into your cluster.
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - github.com/fluxcd/flux2/manifests/install?ref=v2.2.2
patches:
  # Remove the default network policies
  - patch: |-
      $patch: delete
      apiVersion: networking.k8s.io/v1
      kind: NetworkPolicy
      metadata:
        name: not-used
    target:
      group: networking.k8s.io
      kind: NetworkPolicy
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-settings
  namespace: flux-system
data:
  TIMEZONE: "Europe/Berlin"
  COREDNS_ADDR: "10.43.0.10"
  KUBE_VIP_ADDR: "192.168.31.60"
  CLUSTER_CIDR: "10.42.0.0/16"
  SERVICE_CIDR: "10.43.0.0/16"
  NODE_CIDR: "192.168.31.0/24"
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./cluster-settings.yaml
  - ./cluster-settings-user.yaml
  - ./cluster-secrets.sops.yaml
  - ./cluster-secrets-user.sops.yaml
apiVersion: v1
kind: Secret
metadata:
    name: cluster-secrets
    namespace: flux-system
stringData:
    SECRET_ACME_EMAIL: ENC[AES256_GCM,data:ag4/BYYLMG2S92gl8ra22Zk=,iv:iJ/n4IyQukdqaV5g3xO2m832V32ipAoxrMP6cqQBnhw=,tag:CygPsGoe3bxf0uRTqCiWSQ==,type:str]
    SECRET_CLOUDFLARE_TUNNEL_ID: ENC[AES256_GCM,data:a7w/EmQOMEz5KAHMUmfyr17XAl5qLg9KOdXmUdibJaqHbBLt,iv:QHj9c7gOvMi8ifeZbplxBACPtIshIho4ZeIscnFcbDw=,tag:kiodQtkXqHjnN4NUnhKxVA==,type:str]
    SECRET_DOMAIN: ENC[AES256_GCM,data:ZH3E+EjCku/+B5I+N5o=,iv:ESQYDtimjXDxNoThRWPXqgH8v8PvOFm7pt1wDL1tiAU=,tag:EGa9heGZ1d84hKg9DOrnpg==,type:str]
sops:
    kms: []
    gcp_kms: []
    azure_kv: []
    hc_vault: []
    age:
        - recipient: age1nw624gkjpl0sattullahnekdswjcvsgarf8gwwyf9jdqc0zm9enqyp2pf6
          enc: |
            -----BEGIN AGE ENCRYPTED FILE-----
            YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSBiV2xvVTFRVEJzRFNTVUZR
            R1ArNWJ5bzB1b3BOTFBrNUdXd1p6Q3FNbldNCjRma29mdzRnNXI3dHRZU2tMTEo3
            Tm9NWDRkSm5GVGRINC9KWWFzU0lXQjQKLS0tIGVpNTF1YmdjVndDajREcEUzbTRC
            UDhXdzRIVWtoeGlnYUZNMHc0M0lmeUUKiZOXr5Tm6NGFZPahwEgQ5UmvXeOHUx9j
            7Rzlbozddhp0CiGX71cwcDFrsNM7c15rqhd5Ozd4HIRXj8v+5TEjKQ==
            -----END AGE ENCRYPTED FILE-----
    lastmodified: "2023-12-28T21:40:21Z"
    mac: ENC[AES256_GCM,data:CUOyoARsrPdu/WtUuKeGQ6Fpm6RIDE3Qe52ddnFehrsagC1N2qCNQDl/r84Y4YpqnzCjGIonFLEs5ALAhp+pQYxDPONIJBKT4YlpsC4ToG3CNewbGUdXzzzO09A0C041ZC3Le2PeP5Tby9NxzXkWH/sftdpujuSBoRUiOVsqdoY=,iv:uoVT2hCElNIckCUQytmrDLuUpFeII1kWwUgY/3olP7o=,tag:6rwlM1dzKZa06WpGXCXQ1w==,type:str]
    pgp: []
    encrypted_regex: ^(data|stringData)$
    version: 3.8.1
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-settings-user
  namespace: flux-system
data:
  SETTINGS_PLACEHOLDER: "settings-value"
apiVersion: v1
kind: Secret
metadata:
    name: cluster-secrets-user
    namespace: flux-system
stringData:
    SECRET_PLACEHOLDER: ENC[AES256_GCM,data:/oQCtSnNm4mqm6Ui,iv:CsdkM/2OVfgyWG47CuwhvTa8ubb5AvL2H27On/i7ykE=,tag:iuu+ZdilvqViBsORPLFuKw==,type:str]
    ADMIN_PASSWORD: ENC[AES256_GCM,data:av4hd5aUHA==,iv:WgLFIH2/950lzElhoKN4C/tSwT+m+c42ztLpVs0HtgM=,tag:Suv6oJ2msuUjE1IiDBPGzg==,type:str]
sops:
    kms: []
    gcp_kms: []
    azure_kv: []
    hc_vault: []
    age:
        - recipient: age1nw624gkjpl0sattullahnekdswjcvsgarf8gwwyf9jdqc0zm9enqyp2pf6
          enc: |
            -----BEGIN AGE ENCRYPTED FILE-----
            YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSBIbjQ3ZDdyLytNMmM3ZVAy
            Z0JmL0dWb2RZL0RkTWtSQ2JWYWZDb1RXTmdvCjZFem1zTElPRUFmU2VOY3dQSmd6
            ZGw1ZDlPdEFrU0NhTlhFdzhiaHZiazgKLS0tIFM0Y2RSWEdlMk9wcmNlSnEwTFpQ
            Zm84N2FrZ3pOWmwvclJSclRzRFJMN3cKqb6CJXe7lVXUUXaJDoIKdd3kBNJNoIEJ
            ASe1NCKtzZUaFzw6eQfxWytsXWIs93eagM7NqojZpvx/KjWc6ZIoBA==
            -----END AGE ENCRYPTED FILE-----
    lastmodified: "2023-12-29T00:24:11Z"
    mac: ENC[AES256_GCM,data:JUvTYzuXc8PcivIXZu+YPFft83bl6N//chBhpbTeFlDCBc11i1pojzecSSF1BDbsnYQ919SzfPV4pAN0Wf+UXCJJ2xzsb/+BIMQbr/s+aL/J3kplJa4Tuf1cxtwyJqCvHKldnN8jJEF6f0eNGsoqNxU2QC8x/C/+7PLLdgo5Rzs=,iv:s2JLUsRNTwxWK04e3cwWGuk4eUuq59H06jRwbs2/BwQ=,tag:KqQ8dkCKqtzqoxDuDdE1CA==,type:str]
    pgp: []
    encrypted_regex: ^(data|stringData)$
    version: 3.8.1
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: OCIRepository
metadata:
  name: flux-manifests
  namespace: flux-system
spec:
  interval: 10m
  url: oci://ghcr.io/fluxcd/flux-manifests
  ref:
    tag: v2.2.2
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: flux
  namespace: flux-system
spec:
  interval: 10m
  path: ./
  prune: true
  wait: true
  sourceRef:
    kind: OCIRepository
    name: flux-manifests
  patches:
    # Remove the network policies that does not work with k3s
    - patch: |
        $patch: delete
        apiVersion: networking.k8s.io/v1
        kind: NetworkPolicy
        metadata:
          name: not-used
      target:
        group: networking.k8s.io
        kind: NetworkPolicy
    # Increase the number of reconciliations that can be performed in parallel and bump the resources limits
    # https://fluxcd.io/flux/cheatsheets/bootstrap/#increase-the-number-of-workers
    - patch: |
        - op: add
          path: /spec/template/spec/containers/0/args/-
          value: --concurrent=8
        - op: add
          path: /spec/template/spec/containers/0/args/-
          value: --kube-api-qps=500
        - op: add
          path: /spec/template/spec/containers/0/args/-
          value: --kube-api-burst=1000
        - op: add
          path: /spec/template/spec/containers/0/args/-
          value: --requeue-dependency=5s
      target:
        kind: Deployment
        name: (kustomize-controller|helm-controller|source-controller)
    - patch: |
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: not-used
        spec:
          template:
            spec:
              containers:
                - name: manager
                  resources:
                    limits:
                      cpu: 2000m
                      memory: 2Gi
      target:
        kind: Deployment
        name: (kustomize-controller|helm-controller|source-controller)
    # Enable Helm near OOM detection
    # https://fluxcd.io/flux/cheatsheets/bootstrap/#enable-helm-near-oom-detection
    - patch: |
        - op: add
          path: /spec/template/spec/containers/0/args/-
          value: --feature-gates=OOMWatch=true
        - op: add
          path: /spec/template/spec/containers/0/args/-
          value: --oom-watch-memory-threshold=95
        - op: add
          path: /spec/template/spec/containers/0/args/-
          value: --oom-watch-interval=500ms
      target:
        kind: Deployment
        name: helm-controller
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./flux.yaml
  - ./cluster.yaml
---
apiVersion: source.toolkit.fluxcd.io/v1
kind: GitRepository
metadata:
  name: home-kubernetes
  namespace: flux-system
spec:
  interval: 30m
  ref:
    branch: main
  url: "https://github.com/nachtschatt3n/cberg-home.git"
  ignore: |
    # exclude all
    /*
    # include kubernetes directory
    !/kubernetes
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: cluster
  namespace: flux-system
spec:
  interval: 30m
  path: ./kubernetes/flux
  prune: true
  wait: false
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  decryption:
    provider: sops
    secretRef:
      name: sops-age
  postBuild:
    substituteFrom:
      - kind: ConfigMap
        name: cluster-settings
      - kind: Secret
        name: cluster-secrets
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./git
  - ./helm
  - ./oci
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources: []
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: k8s-gateway
  namespace: flux-system
spec:
  interval: 1h
  url: https://ori-edge.github.io/k8s_gateway/
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: csi-driver-nfs
  namespace: flux-system
spec:
  interval: 1h
  url: https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: ingress-nginx
  namespace: flux-system
spec:
  interval: 1h
  url: https://kubernetes.github.io/ingress-nginx
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: nextcloud
  namespace: flux-system
spec:
  interval: 1h
  url: https://nextcloud.github.io/helm/
  timeout: 3m
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: prometheus-community
  namespace: flux-system
spec:
  type: oci
  interval: 5m
  url: oci://ghcr.io/prometheus-community/charts
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./backube.yaml
  - ./bitnami.yaml
  - ./bjw-s.yaml
  - ./cilium.yaml
  - ./coredns.yaml
  - ./csi-driver-nfs.yaml
  - ./democratic-csi.yaml
  - ./external-dns.yaml
  - ./grafana.yaml
  - ./hajimari.yaml
  - ./influxdata.yaml
  - ./ingress-nginx.yaml
  - ./jetstack.yaml
  - ./k8s-gateway.yaml
  - ./kubernetes-dashboard.yaml
  - ./metrics-server.yaml
  - ./nextcloud.yaml
  - ./piraeus.yaml
  - ./prometheus-community.yaml
  - ./stakater.yaml
  - ./weave-gitops.yaml
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: weave-gitops
  namespace: flux-system
spec:
  type: oci
  interval: 5m
  url: oci://ghcr.io/weaveworks/charts
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: bitnami
  namespace: flux-system
spec:
  type: oci
  interval: 5m
  url: oci://registry-1.docker.io/bitnamicharts
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: stakater
  namespace: flux-system
spec:
  interval: 1h
  url: https://stakater.github.io/stakater-charts
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: bjw-s
  namespace: flux-system
spec:
  type: oci
  interval: 5m
  url: oci://ghcr.io/bjw-s/helm
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: backube
  namespace: flux-system
spec:
  interval: 1h
  url: https://backube.github.io/helm-charts/
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: grafana
  namespace: flux-system
spec:
  interval: 1h
  url: https://grafana.github.io/helm-charts
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: coredns
  namespace: flux-system
spec:
  interval: 1h
  url: https://coredns.github.io/helm
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: influxdata
  namespace: flux-system
spec:
  interval: 1h
  url: https://helm.influxdata.com
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: jetstack
  namespace: flux-system
spec:
  interval: 1h
  url: https://charts.jetstack.io/
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: hajimari
  namespace: flux-system
spec:
  interval: 1h
  url: https://hajimari.io
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: democratic-csi
  namespace: flux-system
spec:
  interval: 1h
  url: https://democratic-csi.github.io/charts/
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: kubernetes-dashboard
  namespace: flux-system
spec:
  interval: 1h
  url: https://kubernetes.github.io/dashboard/
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: metrics-server
  namespace: flux-system
spec:
  interval: 1h
  url: https://kubernetes-sigs.github.io/metrics-server
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: external-dns
  namespace: flux-system
spec:
  interval: 1h
  url: https://kubernetes-sigs.github.io/external-dns
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: piraeus
  namespace: flux-system
spec:
  interval: 1h
  url: https://piraeus.io/helm-charts/
---
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: HelmRepository
metadata:
  name: cilium
  namespace: flux-system
spec:
  interval: 1h
  url: https://helm.cilium.io
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources: []
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: cluster-apps
  namespace: flux-system
spec:
  interval: 30m
  path: ./kubernetes/apps
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  decryption:
    provider: sops
    secretRef:
      name: sops-age
  postBuild:
    substituteFrom:
      - kind: ConfigMap
        name: cluster-settings
      - kind: Secret
        name: cluster-secrets
      - kind: ConfigMap
        name: cluster-settings-user
      - kind: Secret
        name: cluster-secrets-user
  patches:
    - patch: |-
        apiVersion: kustomize.toolkit.fluxcd.io/v1
        kind: Kustomization
        metadata:
          name: not-used
        spec:
          decryption:
            provider: sops
            secretRef:
              name: sops-age
          postBuild:
            substituteFrom:
              - kind: ConfigMap
                name: cluster-settings
              - kind: Secret
                name: cluster-secrets
              - kind: ConfigMap
                name: cluster-settings-user
              - kind: Secret
                name: cluster-secrets-user
      target:
        group: kustomize.toolkit.fluxcd.io
        kind: Kustomization
        labelSelector: substitution.flux.home.arpa/disabled notin (true)
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app weave-gitops
  namespace: flux-system
spec:
  targetNamespace: flux-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/flux-system/weave-gitops/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./secret.sops.yaml
  - ./helmrelease.yaml
apiVersion: v1
kind: Secret
metadata:
    name: cluster-user-auth
stringData:
    password: ENC[AES256_GCM,data:W2k9b51yMz1eNQfV/V1CbahOqnZiX7MdcHrvPz6nAjDdlNKlAySgu4D1dGOUYvpj1Gg8fk311o4t6usy,iv:froo6JXK2MkKUepIPtgF0rbbTqgMBMIMWZZ9XEqEVII=,tag:Tqf1R4Rht4jQIFpLux7ipw==,type:str]
    username: ENC[AES256_GCM,data:LFEkm00=,iv:YFRxOqszldV3Yoi0vc8Pkof6gKEIMLq5LksjYpHuAY8=,tag:orwAVqt58VbSFYHrmOiAug==,type:str]
type: Opaque
sops:
    kms: []
    gcp_kms: []
    azure_kv: []
    hc_vault: []
    age:
        - recipient: age1nw624gkjpl0sattullahnekdswjcvsgarf8gwwyf9jdqc0zm9enqyp2pf6
          enc: |
            -----BEGIN AGE ENCRYPTED FILE-----
            YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSBKTUhmY0RTaFRtRUlJbFBI
            cmpZMVk3RG9xL3Zxa2VCU3B6NjVKd09UendNCmF0Qkx2aGdYWnYvZWN1WGlxbDJN
            YVg2dFIrWis0RXE3L28xM2Nkc1JiVDAKLS0tIDdRbFZkK0Nrd29lZytsWUJxZ2Fa
            eWdpTDNuN2U5VWNwOXRrT21WZXF2TzQKvn6Id66gq8daPGXzjgBq5+nk2qt+4ltD
            3q9RagwuGaaGD2LTjDEyh8OMJNs/oky3ZQVeHDk1oCt2VJAL3eq4EQ==
            -----END AGE ENCRYPTED FILE-----
    lastmodified: "2023-12-28T21:40:40Z"
    mac: ENC[AES256_GCM,data:BlsuWpaSwm/ymR28kO60upeiqdnl+CmLQcR3EnAtE6HWVA1K6VHiV4tednVaNZvDfLYbAy2PluzC+gu8kFLFI7WJWI+aggIj6xmU/oGfoL3KDZ8iApKVrpfiTcUYXfph2ir5RcL0uGx1nvmq9BrBaJqoS6CcI+Ao9IUcyNXakqc=,iv:h6pdhQP5/yjjCmXteQsC+GrSINhfzu9Q6avFzNZE3Hc=,tag:e0RjmsYuFpO2GoHJqEEN8Q==,type:str]
    pgp: []
    encrypted_regex: ^(data|stringData)$
    version: 3.8.1
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: weave-gitops
spec:
  interval: 30m
  chart:
    spec:
      chart: weave-gitops
      version: 4.0.36
      sourceRef:
        kind: HelmRepository
        name: weave-gitops
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    adminUser:
      create: true
      createSecret: false
      username: admin
    ingress:
      enabled: true
      className: internal
      annotations:
        hajimari.io/icon: sawtooth-wave
      hosts:
        - host: &host "gitops.${SECRET_DOMAIN}"
          paths:
            - path: /
              pathType: Prefix
      tls:
        - hosts:
            - *host
    networkPolicy:
      create: false
    metrics:
      enabled: true
    rbac:
      create: true
      impersonationResourceNames: ["admin"]
    podAnnotations:
      secret.reloader.stakater.com/reload: cluster-user-auth
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./namespace.yaml
  - ./addons/ks.yaml
  - ./weave-gitops/ks.yaml
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app flux-webhooks
  namespace: flux-system
spec:
  targetNamespace: flux-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/flux-system/addons/webhooks
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: true
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./github
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: flux-webhook
  annotations:
    external-dns.alpha.kubernetes.io/target: "external.${SECRET_DOMAIN}"
    hajimari.io/enable: "false"
spec:
  ingressClassName: external
  rules:
    - host: &host "flux-webhook.${SECRET_DOMAIN}"
      http:
        paths:
          - path: /hook/
            pathType: Prefix
            backend:
              service:
                name: webhook-receiver
                port:
                  number: 80
  tls:
    - hosts:
        - *host
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./secret.sops.yaml
  - ./ingress.yaml
  - ./receiver.yaml
apiVersion: v1
kind: Secret
metadata:
    name: github-webhook-token-secret
stringData:
    token: ENC[AES256_GCM,data:Je2J2dIQOiBmaCL9Jg0/5KlW4c2V4W+Y,iv:EQr49gOuhhXuFcMclkr2yeVLNSQT28gQ8FDkNgyHZBY=,tag:rIgiYJOh8CWlhbbQ340GjQ==,type:str]
sops:
    kms: []
    gcp_kms: []
    azure_kv: []
    hc_vault: []
    age:
        - recipient: age1nw624gkjpl0sattullahnekdswjcvsgarf8gwwyf9jdqc0zm9enqyp2pf6
          enc: |
            -----BEGIN AGE ENCRYPTED FILE-----
            YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSBZUFlQaVc3UkVOZGoxYlVN
            Mm51NXhnUEN6VHVlTnBRYmVjSXBvTjJJbFhBCi9Rc3F1ckNybGpicFlQcUlRSmVF
            d0FNeTNYc2hranFra2RYQksrTFBDSUkKLS0tIENCTkt3aVVzeUpaVTFkRUlPZ3g2
            Mm9neGYxMDFENFpUblNwSGJEOEF5YmcKZ7Jyrqx//a4o0GJD9aR1CuB0bsI7YMAJ
            r9ECOh70sjBqzSv6yIt8Qaw1JzjaWSIxeQGKkntiV4hAYX7xUL8bCg==
            -----END AGE ENCRYPTED FILE-----
    lastmodified: "2023-12-28T21:40:22Z"
    mac: ENC[AES256_GCM,data:GLraMCSV5wx9kdKnTp77heUpb1GJQqSLZrqzsKe2wntJ4xLjrk5UYhU50vCJqWZwnM70n4QXppcKyRXWmoBEW16yzrLwRsieL7i74qUlHLmSdObN3akgt/UB2f1TEsSEL7OCRK+Dc6IBoAFiueyedNwku8UlTfYpeU2C7nYiMao=,iv:gCZfEgk2fANi/Px4SXL/ohfax5ipH2LnGQsA4HmD5y8=,tag:0Ykde3Ys2o37GYX07aqn5w==,type:str]
    pgp: []
    encrypted_regex: ^(data|stringData)$
    version: 3.8.1
---
apiVersion: notification.toolkit.fluxcd.io/v1
kind: Receiver
metadata:
  name: github-receiver
spec:
  type: github
  events:
    - ping
    - push
  secretRef:
    name: github-webhook-token-secret
  resources:
    - apiVersion: source.toolkit.fluxcd.io/v1
      kind: GitRepository
      name: home-kubernetes
      namespace: flux-system
    - apiVersion: kustomize.toolkit.fluxcd.io/v1
      kind: Kustomization
      name: cluster
      namespace: flux-system
    - apiVersion: kustomize.toolkit.fluxcd.io/v1
      kind: Kustomization
      name: cluster-apps
      namespace: flux-system
---
apiVersion: v1
kind: Namespace
metadata:
  name: flux-system
  labels:
    kustomize.toolkit.fluxcd.io/prune: disabled
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app external-dns
  namespace: flux-system
spec:
  targetNamespace: networking
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/networking/external-dns/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: true
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./dnsendpoint-crd.yaml
  - ./secret.sops.yaml
  - ./helmrelease.yaml
apiVersion: v1
kind: Secret
metadata:
    name: external-dns-secret
stringData:
    api-token: ENC[AES256_GCM,data:k8tRMaAscysi6ZddMEB71e6OTOtmTw/8qWpKHbvJC0p2rr6gayKw2Q==,iv:3SeUmi6bEyQ6+d0wzh0eTv+HxQnyqYBKdmO6ZicWl4E=,tag:wNmxpvkbHeHOIdi1LOswBA==,type:str]
sops:
    kms: []
    gcp_kms: []
    azure_kv: []
    hc_vault: []
    age:
        - recipient: age1nw624gkjpl0sattullahnekdswjcvsgarf8gwwyf9jdqc0zm9enqyp2pf6
          enc: |
            -----BEGIN AGE ENCRYPTED FILE-----
            YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSBCYU0xMVQvN3RPUXZ4cW1t
            WWdtZE9ndi9QalowRGcyVmxMVExacWNoeERRCjlMSVdkZ2NjWGtCOGtxVHphM08v
            UmpSQ3A4eHk1MTQ3N1hJbjg3Z1o0V1EKLS0tIDF3aUdIVzc2UEpSMXZ5UVV2dTdz
            SWxKbXpMSHZHOHpZQUFPdlZtcm4wVVUKeQy3tFsamEUh6Y7sB//YQua8y64ZNvIW
            ZFbckBoWVWsZrGgMMHu4CwU3sdUJNLYHlSX8gMM1KuXXOtQpxeZR1g==
            -----END AGE ENCRYPTED FILE-----
    lastmodified: "2023-12-28T21:40:22Z"
    mac: ENC[AES256_GCM,data:1BsPLUZGtGLF1TKsrQI7SQe4AcfJgMEFRu3K3fKfqWan4fw1ZBC4SaeoN8OPw+jmyJC6juh8UIZG5DjVCihPxXTjGj/r49IcPiDLzcUslCk4gyvHgp0gwM2GT1HG2rGdTZQy+rs20yT10R+xuVY3V2XRKyawuPK78puSl1ZfP2s=,iv:neXcj2mq+gVPQk333SYrFCMjiGCvTiYxutaY+3CVM0g=,tag:I9LqVhTLnL8e2QmBhsKKtA==,type:str]
    pgp: []
    encrypted_regex: ^(data|stringData)$
    version: 3.8.1
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: &app external-dns
spec:
  interval: 30m
  chart:
    spec:
      chart: external-dns
      version: 1.13.1
      sourceRef:
        kind: HelmRepository
        name: external-dns
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    fullnameOverride: *app
    provider: cloudflare
    env:
      - name: CF_API_TOKEN
        valueFrom:
          secretKeyRef:
            name: external-dns-secret
            key: api-token
    extraArgs:
      - --ingress-class=external
      - --cloudflare-proxied
      - --crd-source-apiversion=externaldns.k8s.io/v1alpha1
      - --crd-source-kind=DNSEndpoint
    policy: sync
    sources: ["crd", "ingress"]
    txtPrefix: k8s.
    txtOwnerId: default
    domainFilters: ["${SECRET_DOMAIN}"]
    serviceMonitor:
      enabled: true
    podAnnotations:
      secret.reloader.stakater.com/reload: external-dns-secret
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.5.0
    api-approved.kubernetes.io: "https://github.com/kubernetes-sigs/external-dns/pull/2007"
  creationTimestamp: null
  name: dnsendpoints.externaldns.k8s.io
spec:
  group: externaldns.k8s.io
  names:
    kind: DNSEndpoint
    listKind: DNSEndpointList
    plural: dnsendpoints
    singular: dnsendpoint
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema:
      openAPIV3Schema:
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            description: DNSEndpointSpec defines the desired state of DNSEndpoint
            properties:
              endpoints:
                items:
                  description: Endpoint is a high-level way of a connection between a service and an IP
                  properties:
                    dnsName:
                      description: The hostname of the DNS record
                      type: string
                    labels:
                      additionalProperties:
                        type: string
                      description: Labels stores labels defined for the Endpoint
                      type: object
                    providerSpecific:
                      description: ProviderSpecific stores provider specific config
                      items:
                        description: ProviderSpecificProperty holds the name and value of a configuration which is specific to individual DNS providers
                        properties:
                          name:
                            type: string
                          value:
                            type: string
                        type: object
                      type: array
                    recordTTL:
                      description: TTL for the record
                      format: int64
                      type: integer
                    recordType:
                      description: RecordType type of record, e.g. CNAME, A, SRV, TXT etc
                      type: string
                    setIdentifier:
                      description: Identifier to distinguish multiple records with the same name and type (e.g. Route53 records with routing policies other than 'simple')
                      type: string
                    targets:
                      description: The targets the DNS record points to
                      items:
                        type: string
                      type: array
                  type: object
                type: array
            type: object
          status:
            description: DNSEndpointStatus defines the observed state of DNSEndpoint
            properties:
              observedGeneration:
                description: The generation observed by the external-dns controller.
                format: int64
                type: integer
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./namespace.yaml
  - ./cloudflared/ks.yaml
  - ./echo-server/ks.yaml
  - ./external-dns/ks.yaml
  - ./k8s-gateway/ks.yaml
  - ./nginx/ks.yaml
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app k8s-gateway
  namespace: flux-system
spec:
  targetNamespace: networking
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/networking/k8s-gateway/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: k8s-gateway
spec:
  interval: 30m
  chart:
    spec:
      chart: k8s-gateway
      version: 2.1.0
      sourceRef:
        kind: HelmRepository
        name: k8s-gateway
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    fullnameOverride: k8s-gateway
    domain: "${SECRET_DOMAIN}"
    ttl: 1
    service:
      type: LoadBalancer
      port: 53
      annotations:
        io.cilium/lb-ipam-ips: "192.168.31.61"
      externalTrafficPolicy: Cluster
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app echo-server
  namespace: flux-system
spec:
  targetNamespace: networking
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/networking/echo-server/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: echo-server
spec:
  interval: 30m
  chart:
    spec:
      chart: app-template
      version: 2.4.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    controllers:
      main:
        replicas: 2
        strategy: RollingUpdate
        containers:
          main:
            image:
              repository: docker.io/jmalloc/echo-server
              tag: 0.3.6
            env:
              PORT: &port 8080
            probes:
              liveness: &probes
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /health
                    port: *port
                  initialDelaySeconds: 0
                  periodSeconds: 10
                  timeoutSeconds: 1
                  failureThreshold: 3
              readiness: *probes
              startup:
                enabled: false
            resources:
              requests:
                cpu: 5m
                memory: 10M
              limits:
                memory: 64M
        pod:
          securityContext:
            runAsUser: 568
            runAsGroup: 568
    service:
      main:
        ports:
          http:
            port: *port
    ingress:
      main:
        enabled: true
        className: external
        annotations:
          external-dns.alpha.kubernetes.io/target: "external.${SECRET_DOMAIN}"
          hajimari.io/icon: video-input-antenna
        hosts:
          - host: &host "{{ .Release.Name }}.${SECRET_DOMAIN}"
            paths:
              - path: /
                service:
                  name: main
                  port: http
        tls:
          - hosts:
              - *host
---
apiVersion: v1
kind: Namespace
metadata:
  name: networking
  labels:
    kustomize.toolkit.fluxcd.io/prune: disabled
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app nginx-certificates
  namespace: flux-system
spec:
  targetNamespace: networking
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  dependsOn:
    - name: cert-manager-issuers
  path: ./kubernetes/apps/networking/nginx/certificates
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: true
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app nginx-external
  namespace: flux-system
spec:
  targetNamespace: networking
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  dependsOn:
    - name: nginx-certificates
  path: ./kubernetes/apps/networking/nginx/external
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app nginx-internal
  namespace: flux-system
spec:
  targetNamespace: networking
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  dependsOn:
    - name: nginx-certificates
  path: ./kubernetes/apps/networking/nginx/internal
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: nginx-internal
  namespace: &namespace networking
spec:
  interval: 30m
  chart:
    spec:
      chart: ingress-nginx
      version: 4.7.1
      sourceRef:
        kind: HelmRepository
        name: ingress-nginx
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    fullnameOverride: nginx-internal
    controller:
      replicaCount: 1
      service:
        annotations:
          external-dns.alpha.kubernetes.io/hostname: "internal.${SECRET_DOMAIN}"
          io.cilium/lb-ipam-ips: "192.168.31.63"
        externalTrafficPolicy: Cluster
      ingressClassResource:
        name: internal
        default: true
        controllerValue: k8s.io/internal
      admissionWebhooks:
        objectSelector:
          matchExpressions:
            - key: ingress-class
              operator: In
              values: ["internal"]
      config:
        client-body-buffer-size: 100M
        client-body-timeout: 120
        client-header-timeout: 120
        enable-brotli: "true"
        enable-real-ip: "true"
        hsts-max-age: 31449600
        keep-alive-requests: 10000
        keep-alive: 120
        log-format-escape-json: "true"
        log-format-upstream: >
          {"time": "$time_iso8601", "remote_addr": "$proxy_protocol_addr", "x_forwarded_for": "$proxy_add_x_forwarded_for",
          "request_id": "$req_id", "remote_user": "$remote_user", "bytes_sent": $bytes_sent, "request_time": $request_time,
          "status": $status, "vhost": "$host", "request_proto": "$server_protocol", "path": "$uri", "request_query": "$args",
          "request_length": $request_length, "duration": $request_time, "method": "$request_method", "http_referrer": "$http_referer",
          "http_user_agent": "$http_user_agent"}
        proxy-body-size: 0
        proxy-buffer-size: 16k
        ssl-protocols: TLSv1.3 TLSv1.2
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
          namespace: *namespace
          namespaceSelector:
            any: true
      extraArgs:
        default-ssl-certificate: "networking/${SECRET_DOMAIN/./-}-production-tls"
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: ingress-nginx
              app.kubernetes.io/instance: nginx-internal
              app.kubernetes.io/component: controller
      resources:
        requests:
          cpu: 10m
          memory: 250Mi
        limits:
          memory: 500Mi
    defaultBackend:
      enabled: false
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: "${SECRET_DOMAIN/./-}-staging"
spec:
  secretName: "${SECRET_DOMAIN/./-}-staging-tls"
  issuerRef:
    name: letsencrypt-staging
    kind: ClusterIssuer
  commonName: "${SECRET_DOMAIN}"
  dnsNames:
    - "${SECRET_DOMAIN}"
    - "*.${SECRET_DOMAIN}"
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./staging.yaml
  - ./production.yaml
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: "${SECRET_DOMAIN/./-}-production"
spec:
  secretName: "${SECRET_DOMAIN/./-}-production-tls"
  issuerRef:
    name: letsencrypt-production
    kind: ClusterIssuer
  commonName: "${SECRET_DOMAIN}"
  dnsNames:
    - "${SECRET_DOMAIN}"
    - "*.${SECRET_DOMAIN}"
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: nginx-external
  namespace: &namespace networking
spec:
  interval: 30m
  chart:
    spec:
      chart: ingress-nginx
      version: 4.7.1
      sourceRef:
        kind: HelmRepository
        name: ingress-nginx
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  dependsOn:
    - name: cloudflared
      namespace: networking
  values:
    fullnameOverride: nginx-external
    controller:
      replicaCount: 1
      service:
        annotations:
          external-dns.alpha.kubernetes.io/hostname: "external.${SECRET_DOMAIN}"
          io.cilium/lb-ipam-ips: "192.168.31.62"
        externalTrafficPolicy: Cluster
      ingressClassResource:
        name: external
        default: false
        controllerValue: k8s.io/external
      admissionWebhooks:
        objectSelector:
          matchExpressions:
            - key: ingress-class
              operator: In
              values: ["external"]
      config:
        client-body-buffer-size: 100M
        client-body-timeout: 120
        client-header-timeout: 120
        enable-brotli: "true"
        enable-real-ip: "true"
        hsts-max-age: 31449600
        keep-alive-requests: 10000
        keep-alive: 120
        log-format-escape-json: "true"
        log-format-upstream: >
          {"time": "$time_iso8601", "remote_addr": "$proxy_protocol_addr", "x_forwarded_for": "$proxy_add_x_forwarded_for",
          "request_id": "$req_id", "remote_user": "$remote_user", "bytes_sent": $bytes_sent, "request_time": $request_time,
          "status": $status, "vhost": "$host", "request_proto": "$server_protocol", "path": "$uri", "request_query": "$args",
          "request_length": $request_length, "duration": $request_time, "method": "$request_method", "http_referrer": "$http_referer",
          "http_user_agent": "$http_user_agent"}
        proxy-body-size: 0
        proxy-buffer-size: 16k
        ssl-protocols: TLSv1.3 TLSv1.2
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
          namespace: *namespace
          namespaceSelector:
            any: true
      extraArgs:
        default-ssl-certificate: "networking/${SECRET_DOMAIN/./-}-production-tls"
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: ingress-nginx
              app.kubernetes.io/instance: nginx-external
              app.kubernetes.io/component: controller
      resources:
        requests:
          cpu: 10m
          memory: 250Mi
        limits:
          memory: 500Mi
    defaultBackend:
      enabled: false
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app cloudflared
  namespace: flux-system
spec:
  targetNamespace: networking
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  dependsOn:
    - name: external-dns
  path: ./kubernetes/apps/networking/cloudflared/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: externaldns.k8s.io/v1alpha1
kind: DNSEndpoint
metadata:
  name: cloudflared
spec:
  endpoints:
    - dnsName: "external.${SECRET_DOMAIN}"
      recordType: CNAME
      targets: ["${SECRET_CLOUDFLARE_TUNNEL_ID}.cfargotunnel.com"]
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./dnsendpoint.yaml
  - ./secret.sops.yaml
  - ./helmrelease.yaml
configMapGenerator:
  - name: cloudflared-configmap
    files:
      - ./configs/config.yaml
generatorOptions:
  disableNameSuffixHash: true
apiVersion: v1
kind: Secret
metadata:
    name: cloudflared-secret
stringData:
    TUNNEL_ID: ENC[AES256_GCM,data:bFjZtTfjX0KcZYRLuHyXrvrL+7sSHWt5UwewpYwbSewg1h1j,iv:ezokfU0fjuEZHVzgc54bYfH4S7xGpi+pmfF/T2ZYp+s=,tag:og17+Xr+vWqCgL7haVi4Wg==,type:str]
    credentials.json: ENC[AES256_GCM,data:tJl0Cr5Ip5ss37OACQk7eOr9/+won6CqF2sYoOZZ2Dk9s1fyPdTjwul16UNw8ctDqoU5c+mjHsGN0ELonNJuYykawEgy6UMyIYDu6GEZ8ICNVnO8a3V0VcCfDlI+O61gPAX1jBjtfPPEzBMDyrxYkgyxBZjNF3x/185p+ZZm04JOoZOqeyO1eYBt21n2MtW7aOmBUbFSMDaUoo7mRAegu2TE4wQId+uSFK0s3R0KzQ==,iv:pzMEGVrE/NjXY+3DDAU2aB52Aj6u+NeEfmgrMwCO6Es=,tag:ashAIeSrspDgONzTpNnLtA==,type:str]
sops:
    kms: []
    gcp_kms: []
    azure_kv: []
    hc_vault: []
    age:
        - recipient: age1nw624gkjpl0sattullahnekdswjcvsgarf8gwwyf9jdqc0zm9enqyp2pf6
          enc: |
            -----BEGIN AGE ENCRYPTED FILE-----
            YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSBtMXVjT3EzY0Z4aGlTMzRh
            ajd3aHQ1TlB1WUk3NVNQRGIzUzBzWjUzQkY4CmYxcVl5R2dickNpOXczNVo5NXR3
            UStrTnVuTHV0Wk4xWEZML28yZ1FlMncKLS0tIG1SVXQyMU5Od21jRjJaZmluTmVr
            Y0xPYmQ1akNsdEN4NmtLaEVrbFBlVGMKkvKyB8+O5drR72FTVOyKrasbR2TvyKVo
            1kUOs3sQo+/plGXQ6PtdsVdOaWvQyUWW/in4g3lUw26KICaGNjl7qA==
            -----END AGE ENCRYPTED FILE-----
    lastmodified: "2023-12-28T21:40:22Z"
    mac: ENC[AES256_GCM,data:wJ6yY4I3XFCvEYGCfHobItWC7ku6vzX6u+5a8bYlTODN9QUemwf4osg8Yyf08IoAQS+ec5W5kiOktSzNrocvni0w4q8MbV94XDDJgUPO7NGb5dXp2A5TFzE9weiciufG6I8QZUIgGgcovZNmdu1iP5d0tGjC/dEHRR3CZG7NrMk=,iv:pecpJSm0gIAeh5hcEIM5dN1/w5wvv4pc9pzyPLXo6MU=,tag:kKQztbBcAUFAqNhwKhQVHQ==,type:str]
    pgp: []
    encrypted_regex: ^(data|stringData)$
    version: 3.8.1
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: cloudflared
spec:
  interval: 30m
  chart:
    spec:
      chart: app-template
      version: 2.4.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    controllers:
      main:
        replicas: 2
        strategy: RollingUpdate
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          main:
            image:
              repository: docker.io/cloudflare/cloudflared
              tag: 2023.10.0
            env:
              NO_AUTOUPDATE: "true"
              TUNNEL_CRED_FILE: /etc/cloudflared/creds/credentials.json
              TUNNEL_METRICS: 0.0.0.0:8080
              TUNNEL_TRANSPORT_PROTOCOL: quic
              TUNNEL_POST_QUANTUM: true
              TUNNEL_ID:
                valueFrom:
                  secretKeyRef:
                    name: cloudflared-secret
                    key: TUNNEL_ID
            args:
              - tunnel
              - --config
              - /etc/cloudflared/config/config.yaml
              - run
              - "$(TUNNEL_ID)"
            probes:
              liveness: &probes
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /ready
                    port: &port 8080
                  initialDelaySeconds: 0
                  periodSeconds: 10
                  timeoutSeconds: 1
                  failureThreshold: 3
              readiness: *probes
              startup:
                enabled: false
            resources:
              requests:
                cpu: 5m
                memory: 128M
              limits:
                memory: 256M
        pod:
          securityContext:
            runAsUser: 568
            runAsGroup: 568
    service:
      main:
        ports:
          http:
            port: *port
    serviceMonitor:
      main:
        enabled: true
    persistence:
      config:
        enabled: true
        type: configMap
        name: cloudflared-configmap
        globalMounts:
          - path: /etc/cloudflared/config/config.yaml
            subPath: config.yaml
            readOnly: true
      creds:
        type: secret
        name: cloudflared-secret
        globalMounts:
          - path: /etc/cloudflared/creds/credentials.json
            subPath: credentials.json
            readOnly: true
---
originRequest:
  http2Origin: true

ingress:
  - hostname: "${SECRET_DOMAIN}"
    service: https://nginx-external-controller.networking.svc.cluster.local:443
    originRequest:
      originServerName: "external.${SECRET_DOMAIN}"
  - hostname: "*.${SECRET_DOMAIN}"
    service: https://nginx-external-controller.networking.svc.cluster.local:443
    originRequest:
      originServerName: "external.${SECRET_DOMAIN}"
  - service: http_status:404
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./namespace.yaml
  - ./cert-manager/ks.yaml
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app cert-manager
  namespace: flux-system
spec:
  targetNamespace: cert-manager
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/cert-manager/cert-manager/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: true
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app cert-manager-issuers
  namespace: flux-system
spec:
  targetNamespace: cert-manager
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  dependsOn:
    - name: cert-manager
  path: ./kubernetes/apps/cert-manager/cert-manager/issuers
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: true
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
  - ./prometheusrule.yaml
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: cert-manager.rules
spec:
  groups:
    - name: cert-manager
      rules:
        - alert: CertManagerAbsent
          expr: |
            absent(up{job="cert-manager"})
          for: 15m
          labels:
            severity: critical
          annotations:
            description: >
              New certificates will not be able to be minted, and existing ones can't be renewed until cert-manager is back.
            runbook_url: https://gitlab.com/uneeq-oss/cert-manager-mixin/-/blob/master/RUNBOOK.md#certmanagerabsent
            summary: "Cert Manager has dissapeared from Prometheus service discovery."
    - name: certificates
      rules:
        - alert: CertManagerCertExpirySoon
          expr: |
            avg by (exported_namespace, namespace, name) (certmanager_certificate_expiration_timestamp_seconds - time()) < (21 * 24 * 3600)
          for: 15m
          labels:
            severity: warning
          annotations:
            description: >
              The domain that this cert covers will be unavailable after
              {{ $value | humanizeDuration }}. Clients using endpoints that this cert
              protects will start to fail in {{ $value | humanizeDuration }}.
            runbook_url: https://gitlab.com/uneeq-oss/cert-manager-mixin/-/blob/master/RUNBOOK.md#certmanagercertexpirysoon
            summary: |
              The cert {{ $labels.name }} is {{ $value | humanizeDuration }} from expiry, it should have renewed over a week ago.
        - alert: CertManagerCertNotReady
          expr: |
            max by (name, exported_namespace, namespace, condition) (certmanager_certificate_ready_status{condition!="True"} == 1)
          for: 15m
          labels:
            severity: critical
          annotations:
            description: >
              This certificate has not been ready to serve traffic for at least
              10m. If the cert is being renewed or there is another valid cert, the ingress
              controller _may_ be able to serve that instead.
            runbook_url: https://gitlab.com/uneeq-oss/cert-manager-mixin/-/blob/master/RUNBOOK.md#certmanagercertnotready
            summary: "The cert {{ $labels.name }} is not ready to serve traffic."
        - alert: CertManagerHittingRateLimits
          expr: |
            sum by (host) (rate(certmanager_http_acme_client_request_count{status="429"}[5m])) > 0
          for: 15m
          labels:
            severity: critical
          annotations:
            description: >
              Depending on the rate limit, cert-manager may be unable to generate certificates for up to a week.
            runbook_url: https://gitlab.com/uneeq-oss/cert-manager-mixin/-/blob/master/RUNBOOK.md#certmanagerhittingratelimits
            summary: "Cert manager hitting LetsEncrypt rate limits."
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: cert-manager
spec:
  interval: 30m
  chart:
    spec:
      chart: cert-manager
      version: v1.13.3
      sourceRef:
        kind: HelmRepository
        name: jetstack
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    installCRDs: true
    extraArgs:
      - --dns01-recursive-nameservers=1.1.1.1:53,9.9.9.9:53
      - --dns01-recursive-nameservers-only
    podDnsPolicy: None
    podDnsConfig:
      nameservers:
        - "1.1.1.1"
        - "9.9.9.9"
    prometheus:
      enabled: true
      servicemonitor:
        enabled: true
        prometheusInstance: monitoring
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./secret.sops.yaml
  - ./issuers.yaml
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-production
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: "${SECRET_ACME_EMAIL}"
    privateKeySecretRef:
      name: letsencrypt-production
    solvers:
      - dns01:
          cloudflare:
            apiTokenSecretRef:
              name: cert-manager-secret
              key: api-token
        selector:
          dnsZones:
            - "${SECRET_DOMAIN}"
---
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-staging
spec:
  acme:
    server: https://acme-staging-v02.api.letsencrypt.org/directory
    email: "${SECRET_ACME_EMAIL}"
    privateKeySecretRef:
      name: letsencrypt-staging
    solvers:
      - dns01:
          cloudflare:
            apiTokenSecretRef:
              name: cert-manager-secret
              key: api-token
        selector:
          dnsZones:
            - "${SECRET_DOMAIN}"
apiVersion: v1
kind: Secret
metadata:
    name: cert-manager-secret
stringData:
    api-token: ENC[AES256_GCM,data:y5e6/LNDvLxVuza7mMem1n0BrL1xc6GT6RZTqdS9LH1J4AtAAHFniw==,iv:VsZk5JFnmEXhWCPXLHPdlWWZA/3f9VmX2x8lSfQ2ync=,tag:Uk7GdvVxyY1zjTgbOxUTig==,type:str]
sops:
    kms: []
    gcp_kms: []
    azure_kv: []
    hc_vault: []
    age:
        - recipient: age1nw624gkjpl0sattullahnekdswjcvsgarf8gwwyf9jdqc0zm9enqyp2pf6
          enc: |
            -----BEGIN AGE ENCRYPTED FILE-----
            YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSAyWTZSeFNSRFB3MkpuWXpr
            OXlSQndIUG0xREVrOTlBSUxLSmR6ZWhpSWtVCnFxRmRYa0hDY1NHQ2pDTjN2SDhn
            ciszR0RPSWJmc0pwZkwvUFd5VENjcXMKLS0tIEovekFoQ0VRMG9JZ2RtV3M5ejc3
            SnpQLzFaQXAxN2xrUFNhN1JUOWl5TW8Kyi8+NZnMon3jxAugM0vqRpV/srxGhNnj
            m/gILpBXqPvKNVMDzjJkihfeTdiVr726M3xj0zoWL6kpnr+6jZAepg==
            -----END AGE ENCRYPTED FILE-----
    lastmodified: "2023-12-28T21:40:23Z"
    mac: ENC[AES256_GCM,data:+G+n2PoVTJVk54aRuZEn6BOSqPtABgwX1ZNGYHD/KtEo+UKywFZ7iClpOTrkDlBV7zlLs218B8lhToe1YO+76dB3C3G95qpNmJM1XxnUzGo2iPpLi2L/rYyQf1/s4JsBlRAInZzmaT0CTQeMpM4O1cwj+ir8ncLgYChHkEo1BtY=,iv:IaLp2+QmA/6ReSDQ2d1/fDaGS0BExMyXNIG48KMerOA=,tag:k4Ofsn2HplaWWCw3/9zFVg==,type:str]
    pgp: []
    encrypted_regex: ^(data|stringData)$
    version: 3.8.1
---
apiVersion: v1
kind: Namespace
metadata:
  name: cert-manager
  labels:
    kustomize.toolkit.fluxcd.io/prune: disabled
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app nextcloud
  namespace: flux-system
spec:
  targetNamespace: default
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/default/nextcloud/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nextcloud-data
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 300Gi
  storageClassName: csi-driver-nfs

---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nextcloud-data
spec:
  capacity:
    storage: 300Gi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: csi-driver-nfs
  mountOptions:
    - nfsvers=4.1
  csi:
    driver: nfs.csi.k8s.io
    volumeHandle: "nas_csi_nextcloud_data"
    volumeAttributes:
      server: "192.168.31.226"
      share: "/mnt/user/k8s_csi_nextcloud"
      subDir: "config"
apiVersion: v1
kind: Secret
metadata:
    name: nextcloud-config
stringData:
    postgres_username: ENC[AES256_GCM,data:whYF05zW6vyjPA==,iv:n9jaqvpXeLRAzhV9KO8hhNgrBmF5FgAdGVyHTDbcHIw=,tag:QcnkukipEmMSawKdRrYFfQ==,type:str]
    postgres_password: ENC[AES256_GCM,data:a4zqVAH8Nn/LuDKLdd56enVvw2sp,iv:Z8diaRBjLOarHrOHJpstMvG7bqMv/6ZeedDi3GfWYT4=,tag:OnhioGpmYg2oxE6gMI01IA==,type:str]
    admin_username: ENC[AES256_GCM,data:hE0=,iv:pgntput9Qg+1Z87Ozc6QFK7IxOhH1Ogzqlp6MUiU6iY=,tag:dzW2XOIoiMxce4mYoy3CHw==,type:str]
    admin_password: ENC[AES256_GCM,data:u7fSTlDKq83gKQ==,iv:S6g7aIE5PEpjgd3dW0tTV/ZWN8L9JGq8qr1CAN4FDg4=,tag:VfkZm1Fsj7nlB+fWLMpNnw==,type:str]
sops:
    kms: []
    gcp_kms: []
    azure_kv: []
    hc_vault: []
    age:
        - recipient: age1nw624gkjpl0sattullahnekdswjcvsgarf8gwwyf9jdqc0zm9enqyp2pf6
          enc: |
            -----BEGIN AGE ENCRYPTED FILE-----
            YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSBucG1MWThhQUo0dHJRR0dF
            L2MzV1d5WVUrcnFUaVZDdk9YZWJPSFFFc0Q4CkRsRHpFMXFQRlU5am5adHJ0aUcr
            d2srbnJmdUN6MmFYclJQNkdyRHUzYjQKLS0tIGwyWG1IRmgrdTdXWjdZR2NLMHVN
            dHAybTJEcWZFYVRydUpnM2RmMXFrRTQKuAn4LPDIc+pnzqc1q2buirkr46tyW/Xx
            9rMFin28snf43aElgUahY4racdaYv1J+igY9diD31S5Lu1IVUeqJWQ==
            -----END AGE ENCRYPTED FILE-----
    lastmodified: "2024-01-01T19:38:40Z"
    mac: ENC[AES256_GCM,data:u+X2KOIWGwRmvTYj8OVmbTjIbhtul3d9I+VGL3P89hp6PZ5qeM1b3Q6w0s1i4vsBIh6rea/4HmiwrQy7CilllHBilXDXXst/oawKEI0135kjnt8efIq3aJZX8lAjXgRNeUG/MqnxKfixGnYbhipla3AWkmf+R6YSJfBk+HPum14=,iv:KcUA5KsJm1pztFDhahxvWm/Bd4SkfVjPhOahQZQlQ1U=,tag:5fb177V8Pa8glU24eIgy1g==,type:str]
    pgp: []
    encrypted_regex: ^(data|stringData)$
    version: 3.8.1
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./secrets.sops.yaml
  - ./config-pvc.yaml
  - ./data-pvc.yaml
  - ./helm-release.yaml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nextcloud-config
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 5Gi
  storageClassName: csi-driver-nfs
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nextcloud-config
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: csi-driver-nfs
  mountOptions:
    - nfsvers=4.1
  csi:
    driver: nfs.csi.k8s.io
    volumeHandle: "nas_csi_nextcloud_config"
    volumeAttributes:
      server: "192.168.31.226"
      share: "/mnt/user/k8s_csi_nextcloud"
      subDir: "config"
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: &app nextcloud
spec:
  interval: 60m
  chart:
    spec:
      chart: *app
      version: 4.5.10
      sourceRef:
        kind: HelmRepository
        name: nextcloud
        namespace: flux-system
      interval: 60m
  timeout: 30m
  maxHistory: 2
  install:
    createNamespace: true
    remediation:
      retries: 1
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 1
  uninstall:
    keepHistory: false
  # Values link: https://github.com/nextcloud/helm/blob/master/charts/nextcloud/values.yaml
  values:
    image:
      repository: nextcloud
      #tag: 28.0.1
      tag: stable
      pullPolicy: IfNotPresent
    replicaCount: 1
    ingress:
      enabled: true
      className: internal
      hosts:
        - host: "nextcloud.${SECRET_DOMAIN}"
          paths:
            - path: /
              pathType: Prefix
              service:
                name: main
                port: http
      tls:
        - hosts:
          - "nextcloud.${SECRET_DOMAIN}"
    nextcloud:
      host: nextcloud.${SECRET_DOMAIN}
      phpConfigs:
      # Default config files
      # IMPORTANT: Will be used only if you put extra configs, otherwise default will come from nextcloud itself
      # Default confgurations can be found here: https://github.com/nextcloud/docker/tree/master/16.0/apache/config
      defaultConfigs:
        # To protect /var/www/html/config
        .htaccess: true
        # Redis default configuration
        redis.config.php: false
        # Apache configuration for rewrite urls
        apache-pretty-urls.config.php: true
        # Define APCu as local cache
        apcu.config.php: true
        # Apps directory configs
        apps.config.php: true
        # Used for auto configure database
        autoconfig.php: true
        # SMTP default configuration
        smtp.config.php: false
      # Extra config files created in /var/www/html/config/
      # ref: https://docs.nextcloud.com/server/15/admin_manual/configuration_server/config_sample_php_parameters.html#multiple-config-php-file
      configs:
        custom.config.php: |-
          <?php
          $CONFIG = array (
            'overwriteprotocol' => 'https',
            'overwrite.cli.url' => 'https://nextcloud.${SECRET_DOMAIN}',
            'filelocking.enabled' => 'true',
            'loglevel' => '2',
            'enable_previews' => true,
            'trusted_domains' =>
              [
                'nextcloud',
                'nextcloud.${SECRET_DOMAIN}'
              ],
            'trusted_proxies' =>
              [
                'nginx'
              ],
            'forwarded_for_headers' =>
              [
                0 => 'X-Forwarded-For',
                1 => 'HTTP_X_FORWARDED_FOR',
              ],
            'default_phone_region' => 'DE',
          );
      strategy:
        type: Recreate

      ##
      ## Extra environment variables
      extraEnv:
      #  - name: SOME_SECRET_ENV
      #    valueFrom:
      #      secretKeyRef:
      #        name: nextcloud
      #        key: secret_key
    # Extra sidecar containers.
    extraSidecarContainers:
      - name: nextcloud-logger
        image: busybox
        command: [/bin/sh, -c, 'while ! test -f "/run/nextcloud/data/nextcloud.log"; do sleep 1; done; tail -n+1 -f /run/nextcloud/data/nextcloud.log']
        volumeMounts:
        - name: nextcloud-data
          mountPath: /run/nextcloud/data
    nginx:
      enabled: false

    internalDatabase:
      enabled: true

    mariadb:
      enabled: true
    postgresql:
      enabled: false
    redis:
      enabled: false

    cronjob:
      enabled: false
      resources:
        limits:
          memory: 1024M
        requests:
          cpu: 40m
          memory: 900M

    service:
      type: ClusterIP
      port: 8080

    persistence:
      enabled: true
      existingClaim: "nextcloud-config"

      nextcloudData:
        enabled: true
        existingClaim: "nextcloud-data"

    resources:
      limits:
        memory: 512M
      requests:
        cpu: 10m
        memory: 334M

    livenessProbe:
      enabled: false
    #   initialDelaySeconds: 10
    #   periodSeconds: 30
    #   timeoutSeconds: 10
    #   failureThreshold: 3
    #   successThreshold: 1
    readinessProbe:
      enabled: false
    #   initialDelaySeconds: 60
    #   periodSeconds: 60
    #   timeoutSeconds: 5
    #   failureThreshold: 10
    #   successThreshold: 1
    startupProbe:
      enabled: false
    #   initialDelaySeconds: 60
    #   periodSeconds: 30
    #   timeoutSeconds: 5
    #   failureThreshold: 10
    #   successThreshold: 1

    hpa:
      enabled: false

    metrics:
      enabled: true
      replicaCount: 1
      https: false
      timeout: 5s

      image:
        repository: xperimental/nextcloud-exporter
        tag: 0.6.2
        pullPolicy: IfNotPresent

      service:
        type: ClusterIP
        annotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "9205"
        labels: {}

      resources:
        limits:
          memory: 64M
        requests:
          cpu: 10m
          memory: 64M

    rbac:
      enabled: false
      serviceaccount:
        create: true
        name: nextcloud-serviceaccount
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./namespace.yaml
  - ./hajimari/ks.yaml
  - ./influxdb/ks.yaml
  - ./iobroker/ks.yaml
  - ./nextcloud/ks.yaml
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app influxdb
  namespace: flux-system
spec:
  targetNamespace: default
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/default/influxdb/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - helmrelease.yaml
  - config-pvc.yaml
  - secret.sops.yaml
apiVersion: v1
kind: Secret
metadata:
    name: influxdb-secret
stringData:
    admin-token: ENC[AES256_GCM,data:UAbcsP9IYjMDmFqWLRSHQQ==,iv:uhOsZpCh0RXOBuFKQK0lQvqEIgXMrIVzxVfLNlc9+c4=,tag:mkMqViDGlPyJM60i7n6HiQ==,type:str]
    admin-password: ENC[AES256_GCM,data:ALfWX/qskg==,iv:jXAE35TK4DmbwGzJujILCZwfZY+3sQKBgWlFWlRbEtg=,tag:ZChg+XpGtAo1KjIqSQkHeA==,type:str]
sops:
    kms: []
    gcp_kms: []
    azure_kv: []
    hc_vault: []
    age:
        - recipient: age1nw624gkjpl0sattullahnekdswjcvsgarf8gwwyf9jdqc0zm9enqyp2pf6
          enc: |
            -----BEGIN AGE ENCRYPTED FILE-----
            YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSB2STJiVjA0dEc3M1FyM3Zp
            TG1BYmdESUI0SEpNc2dvcWE4a2lQT3QvcjNjCklOTXF0ME01bTFxYkk3TEtSaU9H
            RDZ3cENzRUFuVFBRSXJ0MmRqYjBxYW8KLS0tIFNNSnkwUXpzZkhBUy80ZTJ4aTdO
            eFFUUE40cFhHLzc3OXphNmFpdW9iMXcKQVfh9++jicoKK0x7TyK/dpumP+u2IAW0
            Jn8fQQ8Ac87oiqEiGRhP5b7DGICVO9JMyO6I/iFKXB5e4nI9O9vFWg==
            -----END AGE ENCRYPTED FILE-----
    lastmodified: "2023-12-29T12:10:25Z"
    mac: ENC[AES256_GCM,data:YUAvigGgxydDQWDC2f/YPn3kmqBVNCWRBk/E5LfQvaJQKu2R6ygSSIqIvv4Y+Br3NeTobIuyAT+Rfarn9BG4qS9N7cN2UPQZligC0yaiJ2SXDPeFb4RVq8QDSeNDE1MrcMGOQ5VX+KZOx/69ZNvFYb3UrEzKgp5wdLhAOAGjXyw=,iv:h0uO4XSSUt+/lET6tcXHDlOlzxwb98lZmTnwYuVmtyA=,tag:qpCctvmUpGgxZv6fmpWZng==,type:str]
    pgp: []
    encrypted_regex: ^(data|stringData)$
    version: 3.8.1
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: influxdb
  namespace: default
spec:
  interval: 25m
  chart:
    spec:
      # renovate: registryUrl=https://helm.influxdata.com/
      chart: influxdb2
      version: 2.1.0
      sourceRef:
        kind: HelmRepository
        name: influxdata
        namespace: flux-system
      interval: 15m
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  dependsOn:
    - name: local-path-provisioner
      namespace: kube-system
  values:
    image:
      repository: docker.io/library/influxdb
      tag: 2.5.1
      pullPolicy: IfNotPresent
    adminUser:
      create: true
      organization: sc
      bucket: default
      user: "admin"
      retention_policy: "0s"
      existingSecret: influxdb-secret
    pdb:
      create: false
    env:
      - name: TZ
        value: "${TIMEZONE}"
    service:
      type: LoadBalancer
      ports:
        http:
          port: 8086
        rpc:
          enabled: true
          port: 8088
    ingress:
      enabled: true
      ingressClassName: internal
      annotations:
        hajimari.io/enable: "true"
        hajimari.io/appName: "Influx DB"
        hajimari.io/icon: "database"
        hajimari.io/group: "databases"
      hostname: &host "influx.${SECRET_DOMAIN}"
      hosts:
        - *host
      tls:
        - hosts:
            - *host
    persistence:
      enabled: true
      useExisting: true
      name: influxdb2-data
    # resources:
    #   requests:
    #     cpu: 30m
    #     memory: 500M
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  namespace: default
  name: influxdb2-data
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: local-hostpath
  resources:
    requests:
      storage: 20Gi

---
apiVersion: v1
kind: Namespace
metadata:
  name: default
  labels:
    kustomize.toolkit.fluxcd.io/prune: disabled
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app hajimari
  namespace: flux-system
spec:
  targetNamespace: default
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/default/hajimari/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: hajimari
spec:
  interval: 30m
  chart:
    spec:
      chart: hajimari
      version: 2.0.2
      sourceRef:
        kind: HelmRepository
        name: hajimari
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    hajimari:
      title: Hajimari
      darkTheme: espresso
      lightTheme: gazette
      alwaysTargetBlank: true
      showGreeting: true
      showAppGroups: true
      showAppStatus: true
      showBookmarkGroups: true
      showGlobalBookmarks: true
      showAppUrls: true
      createCRAppSample: false
      defaultEnable: true
      namespaceSelector:
        matchNames:
          - default
          - monitoring
          - networking
          - cert-manager
          - kube-system
          - flux-system
          - volsync
      customApps:
        - group: Cluster Services
          apps:
            - name: Hajimari
              url: 'https://hajimari.mathiasuhl.com'
              icon: 'mdi:view-dashboard'
              info: Hajimari Dashboard
            - name: InfluxDB
              url: 'https://influx.mathiasuhl.com'
              icon: 'mdi:database'
              info: InfluxDB
            - name: IoBroker
              url: 'https://iobroker.mathiasuhl.com'
              icon: 'mdi:home-assistant'
              info: IoBroker
            - name: Nextcloud
              url: 'https://nextcloud.mathiasuhl.com'
              icon: 'mdi:cloud'
              info: Nextcloud
            - name: Flux Webhook
              url: 'https://flux-webhook.mathiasuhl.com'
              icon: 'mdi:webhook'
              info: Flux Webhook
            - name: GitOps
              url: 'https://gitops.mathiasuhl.com'
              icon: 'mdi:git'
              info: GitOps
            - name: Hubble
              url: 'https://hubble.mathiasuhl.com'
              icon: 'mdi:network'
              info: Hubble
            - name: Grafana
              url: 'https://grafana.mathiasuhl.com'
              icon: 'mdi:chart-bar'
              info: Grafana
            - name: Prometheus
              url: 'https://prometheus.mathiasuhl.com'
              icon: 'mdi:chart-bar'
              info: Prometheus
            - name: Kubernetes Dashboard
              url: 'https://kubernetes.mathiasuhl.com'
              icon: 'mdi:view-dashboard'
              info: Kubernetes Dashboard
            - name: Echo Server
              url: 'https://echo-server.mathiasuhl.com'
              icon: 'mdi:echo'
              info: Echo Server
      globalBookmarks:
        - group: Documentation
          bookmarks:
            - name: Kubernetes Documentation
              url: 'https://kubernetes.io/docs/'
            - name: Helm Documentation
              url: 'https://helm.sh/docs/'
            - name: FluxCD Documentation
              url: 'https://fluxcd.io/docs/'
            - name: Prometheus Documentation
              url: 'https://prometheus.io/docs/'
            - name: Grafana Documentation
              url: 'https://grafana.com/docs/'
        - group: Tools and Services
          bookmarks:
            - name: GitHub
              url: 'https://github.com/'
            - name: Docker Hub
              url: 'https://hub.docker.com/'
            - name: Quay.io
              url: 'https://quay.io/'
            - name: AWS Console
              url: 'https://aws.amazon.com/console/'
            - name: Google Cloud Console
              url: 'https://console.cloud.google.com/'
        - group: Monitoring and Logging
          bookmarks:
            - name: Prometheus
              url: 'https://prometheus.mathiasuhl.com'
            - name: Grafana
              url: 'https://grafana.mathiasuhl.com'
            - name: Kibana
              url: 'https://kibana.mathiasuhl.com'
        - group: Community and Learning
          bookmarks:
            - name: Stack Overflow
              url: 'https://stackoverflow.com/'
            - name: Kubernetes Slack
              url: 'https://slack.k8s.io/'
            - name: CNCF Landscape
              url: 'https://landscape.cncf.io/'
            - name: Dev.to
              url: 'https://dev.to/'
            - name: Medium (DevOps)
              url: 'https://medium.com/tag/devops'
        - group: News
          bookmarks:
            - name: Fefe Blog
              url: 'https://blog.fefe.de/'
            - name: Heise
              url: 'https://heise.de'
            - name: Tageschau
              url: 'https://tageschau.de'
            - name: Golem
              url: 'https://golem.de'
    serviceAccount:
      create: true
    ingress:
      main:
        enabled: true
        ingressClassName: internal
        annotations:
          hajimari.io/enable: "false"
        hosts:
          - host: &host "hajimari.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
        tls:
          - hosts:
              - *host
    podAnnotations:
      configmap.reloader.stakater.com/reload: hajimari-settings
    persistence:
      data:
        enabled: true
        type: emptyDir
    resources:
      requests:
        cpu: 100m
        memory: 128M
      limits:
        cpu: 200m
        memory: 256M
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 30
      periodSeconds: 30
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 30
      periodSeconds: 30
    securityContext:
      runAsUser: 1000
      runAsGroup: 3000
      fsGroup: 2000
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app iobroker
  namespace: flux-system
spec:
  targetNamespace: default
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/default/iobroker/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - helm-release.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: iobroker
  namespace: default
spec:
  interval: 15m
  chart:
    spec:
      chart: app-template
      version: 2.4.0
      interval: 15m
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  install:
    remediation:
      retries: 1
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 1
  dependsOn:
    - name: local-path-provisioner
      namespace: kube-system
  values:
    defaultPodOptions:
      hostname: iobroker
    controllers:
      main:
        type: statefulset
        strategy: RollingUpdate
        containers:
          main:
            nameOverride: iobroker
            image:
              repository: buanet/iobroker
              tag: v9.1.2
              pullPolicy: IfNotPresent

            # -- environment variables.
            # See [image docs](https://docs.buanet.de/iobroker-docker-image/docs/) for more details.
            env:
              - name: AVAHI
                value: "false"
              #- name: DEBUG
              #  value: "false"
              # - name: IOB_ADMINPORT
              #   value: "8081"
              - name: IOB_BACKITUP_EXTDB
                value: "true"
              # - name: IOB_MULTIHOST
              #   value: "none"
              # - name: IOB_OBJECTSDB_HOST
              #   value: "127.0.0.1"
              # - name: IOB_OBJECTSDB_PORT
              #   value: "9001"
              # - name: IOB_OBJECTSDB_TYPE
              #   value: "jsonl" / "file" / "redis"
              # - name: IOB_STATESDB_HOST
              #   value: "127.0.0.1"
              # - name: IOB_STATESDB_PORT
              #   value: "9000"
              # - name: IOB_STATESDB_TYPE
              #   value: "jsonl" / "file" / "redis"
              - name: LANG
                value: "de_DE.UTF-8"
              - name: LANGUAGE
                value: "de_DE.UTF-8"
              - name: LC_ALL
                value: "de_DE.UTF-8"
              - name: PACKAGES
                value: "influxdb2-cli"
                #value: "default-mysql-client influxdb2-cli redis-tools"
              - name: PERMISSION_CHECK
                value: "true"
              # - name: SETGID
              #  value: "1000"
              # - name: SETUID
              #  value: "1000"
              - name: TZ
                value: "Europe/Berlin"
              # - name: USBDEVICES
              #  value: "/dev/ttyACM0"
              # - name: ZWAVE
              #  value: "false"

            probes:
              # -- Liveness probe configuration
              # @default -- See below
              liveness:
                # -- Enable the liveness probe
                enabled: true
                # -- Set this to `true` if you wish to specify your own livenessProbe
                custom: false
                # -- sets the probe type when not using a custom probe
                # @default -- "TCP"
                type: TCP
                # -- The spec field contains the values for the default livenessProbe.
                # If you selected `custom: true`, this field holds the definition of the livenessProbe.
                # @default -- See below
                spec:
                  initialDelaySeconds: 20
                  periodSeconds: 30
                  timeoutSeconds: 1
                  failureThreshold: 3

              # -- Redainess probe configuration
              # @default -- See below
              readiness:
                # -- Enable the readiness probe
                enabled: true
                # -- Set this to `true` if you wish to specify your own readinessProbe
                custom: false
                # -- sets the probe type when not using a custom probe
                # @default -- "TCP"
                type: TCP
                # -- The spec field contains the values for the default readinessProbe.
                # If you selected `custom: true`, this field holds the definition of the readinessProbe.
                # @default -- See below
                spec:
                  initialDelaySeconds: 0
                  periodSeconds: 10
                  timeoutSeconds: 1
                  failureThreshold: 3

              # -- Startup probe configuration
              # @default -- See below
              startup:
                # -- Enable the startup probe
                enabled: true
                # -- Set this to `true` if you wish to specify your own startupProbe
                custom: false
                # -- sets the probe type when not using a custom probe
                # @default -- "TCP"
                type: TCP
                # -- The spec field contains the values for the default startupProbe.
                # If you selected `custom: true`, this field holds the definition of the startupProbe.
                # @default -- See below
                spec:
                  initialDelaySeconds: 0
                  timeoutSeconds: 1
                  ## This means it has a maximum of 5*30=150 seconds to start up before it fails
                  periodSeconds: 15
                  failureThreshold: 30
    service:
      main:
        type: LoadBalancer
        ports:
          http:
            enabled: true
            port: 8081
          vis:
            enabled: true
            port: 8082
          iobrokerapi:
            enabled: true
            port: 8087
          lovelace:
            enabled: true
            port: 8091
          nodered:
            enabled: true
            port: 1880
          states:
            enabled: true
            port: 9000
          objects:
            enabled: true
            port: 9001
          mqtt:
            protocol: TCP
            enabled: true
            port: 1883
          mqttws:
            protocol: TCP
            enabled: true
            port: 1884
          mqttshelly:
            protocol: TCP
            enabled: true
            port: 1885
          nuki:
            protocol: TCP
            enabled: true
            port: 51989
          alexa2-proxy:
            protocol: TCP
            enabled: true
            port: 51988
          avahi:
            protocol: TCP
            enabled: true
            port: 53388
    ingress:
      main:
        enabled: true
        ingressClassName: internal
        annotations:
          hajimari.io/enable: "true"
          hajimari.io/appName: "Iobroker"
        hosts:
          - host: "iobroker.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: main
                  port: http
          - host: "nodered.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: main
                  port: nodered
          - host: "vis.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: main
                  port: vis
          - host: "apiiobroker.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: main
                  port: iobrokerapi
          - host: "lovelace.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: main
                  port: lovelace
        tls:
          - hosts:
            - "iobroker.${SECRET_DOMAIN}"
            - "nodered.${SECRET_DOMAIN}"
            - "vis.${SECRET_DOMAIN}"
            - "iobrokerapi.${SECRET_DOMAIN}"
            - "lovelace.${SECRET_DOMAIN}"
    persistence:
      config-replicated:
        enabled: true
        type: persistentVolumeClaim
        accessMode: ReadWriteOnce
        #storageClass: replicate-nvme
        storageClass: local-hostpath
        size: 10Gi
        globalMounts:
          - path: /opt/iobroker
            readOnly: false
    resources:
      requests:
        cpu: 30m
        memory: 2.5G
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app system-upgrade-controller
  namespace: flux-system
spec:
  targetNamespace: kube-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/kube-system/system-upgrade-controller/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: true
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app system-upgrade-controller-plans
  namespace: flux-system
spec:
  targetNamespace: kube-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  dependsOn:
    - name: system-upgrade-controller
  path: ./kubernetes/apps/kube-system/system-upgrade-controller/plans
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  # renovate: datasource=github-releases depName=rancher/system-upgrade-controller
  - https://github.com/rancher/system-upgrade-controller/releases/download/v0.13.2/crd.yaml
  - helmrelease.yaml
  - rbac.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: &app system-upgrade-controller
spec:
  interval: 30m
  chart:
    spec:
      chart: app-template
      version: 2.4.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    controllers:
      main:
        strategy: RollingUpdate
        containers:
          main:
            image:
              repository: docker.io/rancher/system-upgrade-controller
              tag: v0.13.2
            env:
              SYSTEM_UPGRADE_CONTROLLER_DEBUG: false
              SYSTEM_UPGRADE_CONTROLLER_THREADS: 2
              SYSTEM_UPGRADE_JOB_ACTIVE_DEADLINE_SECONDS: 900
              SYSTEM_UPGRADE_JOB_BACKOFF_LIMIT: 99
              SYSTEM_UPGRADE_JOB_IMAGE_PULL_POLICY: IfNotPresent
              SYSTEM_UPGRADE_JOB_KUBECTL_IMAGE: docker.io/rancher/kubectl:v1.29.0
              SYSTEM_UPGRADE_JOB_PRIVILEGED: true
              SYSTEM_UPGRADE_JOB_TTL_SECONDS_AFTER_FINISH: 900
              SYSTEM_UPGRADE_PLAN_POLLING_INTERVAL: 15m
              SYSTEM_UPGRADE_CONTROLLER_NAME: *app
              SYSTEM_UPGRADE_CONTROLLER_NAMESPACE:
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
        pod:
          securityContext:
            runAsNonRoot: true
            runAsUser: 65534
            runAsGroup: 65534
            allowPrivilegeEscalation: false
            seccompProfile:
              type: RuntimeDefault
            capabilities:
              drop: ["ALL"]
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: node-role.kubernetes.io/control-plane
                        operator: Exists
          tolerations:
            - {key: CriticalAddonsOnly, operator: Exists}
            - {key: node-role.kubernetes.io/master, operator: Exists, effect: NoSchedule}
            - {key: node-role.kubernetes.io/controlplane, operator: Exists, effect: NoSchedule}
            - {key: node-role.kubernetes.io/control-plane, operator: Exists, effect: NoSchedule}
            - {key: node-role.kubernetes.io/etcd, operator: Exists, effect: NoExecute}
    serviceAccount:
      name: system-upgrade
    service:
      main:
        enabled: false
    persistence:
      tmp:
        type: emptyDir
        globalMounts:
          - path: /tmp
      etc-ssl:
        type: hostPath
        hostPath: /etc/ssl
        hostPathType: DirectoryOrCreate
        globalMounts:
          - path: /etc/ssl
            readOnly: true
      etc-pki:
        type: hostPath
        hostPath: /etc/pki
        hostPathType: DirectoryOrCreate
        globalMounts:
          - path: /etc/pki
            readOnly: true
      etc-ca-certificates:
        type: hostPath
        hostPath: /etc/ca-certificates
        hostPathType: DirectoryOrCreate
        globalMounts:
          - path: /etc/ca-certificates
            readOnly: true
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: system-upgrade
secrets:
  - name: system-upgrade
---
apiVersion: v1
kind: Secret
type: kubernetes.io/service-account-token
metadata:
  name: system-upgrade
  annotations:
    kubernetes.io/service-account.name: system-upgrade
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name:  system-upgrade
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: system-upgrade
    namespace: kube-system
---
apiVersion: upgrade.cattle.io/v1
kind: Plan
metadata:
  name: server
spec:
  # renovate: datasource=github-releases depName=k3s-io/k3s
  version: "v1.29.0+k3s1"
  serviceAccountName: system-upgrade
  concurrency: 1
  cordon: true
  nodeSelector:
    matchExpressions:
      - {key: node-role.kubernetes.io/control-plane, operator: Exists}
  tolerations:
    - {effect: NoSchedule, operator: Exists}
    - {effect: NoExecute, operator: Exists}
    - {key: node-role.kubernetes.io/control-plane, effect: NoSchedule, operator: Exists}
    - {key: node-role.kubernetes.io/master, effect: NoSchedule, operator: Exists}
    - {key: node-role.kubernetes.io/etcd, effect: NoExecute, operator: Exists}
    - {key: CriticalAddonsOnly, operator: Exists}
  upgrade:
    image: rancher/k3s-upgrade
---
apiVersion: upgrade.cattle.io/v1
kind: Plan
metadata:
  name: agent
spec:
  # renovate: datasource=github-releases depName=k3s-io/k3s
  version: "v1.29.0+k3s1"
  serviceAccountName: system-upgrade
  concurrency: 1
  nodeSelector:
    matchExpressions:
      - {key: node-role.kubernetes.io/control-plane, operator: DoesNotExist}
  prepare:
    image: rancher/k3s-upgrade
    args: ["prepare", "server"]
  upgrade:
    image: rancher/k3s-upgrade
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./server.yaml
  - ./agent.yaml
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app reloader
  namespace: flux-system
spec:
  targetNamespace: kube-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/kube-system/reloader/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: reloader
  namespace: &namespace kube-system
spec:
  interval: 30m
  chart:
    spec:
      chart: reloader
      version: 1.0.58
      sourceRef:
        kind: HelmRepository
        name: stakater
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    fullnameOverride: reloader
    reloader:
      reloadStrategy: annotations
      podMonitor:
        enabled: true
        namespace: *namespace
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app local-path-provisioner
  namespace: flux-system
  labels:
    substitution.flux.home.arpa/disabled: "true"
spec:
  targetNamespace: kube-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/kube-system/local-path-provisioner/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: local-path-provisioner
spec:
  interval: 30m
  chart:
    spec:
      chart: democratic-csi
      version: 0.14.3
      sourceRef:
        name: democratic-csi
        kind: HelmRepository
        namespace: flux-system
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    fullnameOverride: local-path-provisioner
    controller:
      strategy: node
      externalProvisioner:
        image: registry.k8s.io/sig-storage/csi-provisioner:v3.6.3
        extraArgs:
          - --leader-election=false
          - --node-deployment=true
          - --node-deployment-immediate-binding=false
          - --feature-gates=Topology=true
          - --strict-topology=true
          - --enable-capacity=true
          - --capacity-ownerref-level=1
      externalResizer:
        enabled: false
      externalAttacher:
        enabled: false
      externalSnapshotter:
        enabled: false
    csiDriver:
      name: local-hostpath.cluster.local
      storageCapacity: true
      attachRequired: false
      fsGroupPolicy: File
    storageClasses:
      - name: local-hostpath
        defaultClass: false
        reclaimPolicy: Delete
        volumeBindingMode: WaitForFirstConsumer
        allowVolumeExpansion: true
    driver:
      config:
        driver: local-hostpath
        local-hostpath:
          shareBasePath: &storagePath "/var/lib/rancher/k3s/local-hostpath"
          controllerBasePath: *storagePath
          dirPermissionsMode: "0770"
          dirPermissionsUser: 0
          dirPermissionsGroup: 0
    node:
      driver:
        image: ghcr.io/democratic-csi/democratic-csi:v1.8.4
        extraVolumeMounts:
          - name: local-hostpath
            mountPath: *storagePath
            mountPropagation: Bidirectional
      extraVolumes:
        - name: local-hostpath
          hostPath:
            path: *storagePath
            type: DirectoryOrCreate
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app metrics-server
  namespace: flux-system
spec:
  targetNamespace: kube-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/kube-system/metrics-server/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: metrics-server
spec:
  interval: 30m
  chart:
    spec:
      chart: metrics-server
      version: 3.11.0
      sourceRef:
        kind: HelmRepository
        name: metrics-server
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    args:
      - --kubelet-insecure-tls
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --kubelet-use-node-status-port
      - --metric-resolution=15s
    metrics:
      enabled: true
    serviceMonitor:
      enabled: true
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app csi-driver-nfs
  namespace: flux-system
  labels:
    substitution.flux.home.arpa/disabled: "true"
spec:
  targetNamespace: kube-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/kube-system/csi-driver-nfs/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
# https://github.com/kubernetes-csi/csi-driver-nfs
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: csi-driver-nfs
spec:
  interval: 15m
  chart:
    spec:
      chart: csi-driver-nfs
      version: v4.5.0
      sourceRef:
        kind: HelmRepository
        name: csi-driver-nfs
        namespace: flux-system
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    kubeletDir: /var/lib/kubelet
    controller:
      replicas: 1
    externalSnapshotter:
      enabled: false
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./namespace.yaml
  - ./cilium/ks.yaml
  - ./coredns/ks.yaml
  - ./csi-driver-nfs/ks.yaml
  - ./local-path-provisioner/ks.yaml
  - ./metrics-server/ks.yaml
  - ./reloader/ks.yaml
  - ./snapshot-controller/ks.yaml
  - ./system-upgrade-controller/ks.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: kube-system
  labels:
    kustomize.toolkit.fluxcd.io/prune: disabled
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app coredns
  namespace: flux-system
spec:
  targetNamespace: kube-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/kube-system/coredns/app
  prune: false # never should be deleted
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: coredns
spec:
  interval: 30m
  chart:
    spec:
      chart: coredns
      version: 1.29.0
      sourceRef:
        kind: HelmRepository
        name: coredns
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    fullnameOverride: coredns
    replicaCount: 1
    k8sAppLabelOverride: kube-dns
    service:
      name: kube-dns
      clusterIP: "${COREDNS_ADDR}"
    serviceAccount:
      create: true
    deployment:
      annotations:
        reloader.stakater.com/auto: "true"
    servers:
      - zones:
          - zone: .
            scheme: dns://
            use_tcp: true
        port: 53
        plugins:
          - name: log
          - name: errors
          - name: health
            configBlock: |-
              lameduck 5s
          - name: ready
          - name: kubernetes
            parameters: cluster.local in-addr.arpa ip6.arpa
            configBlock: |-
              pods insecure
              fallthrough in-addr.arpa ip6.arpa
              ttl 30
          - name: prometheus
            parameters: 0.0.0.0:9153
          - name: forward
            parameters: local 192.168.31.25
          - name: forward
            parameters: . /etc/resolv.conf
          - name: cache
            parameters: 30
          - name: loop
          - name: reload
          - name: loadbalance
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: node-role.kubernetes.io/control-plane
                  operator: Exists
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
    topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app.kubernetes.io/instance: coredns
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app cilium
  namespace: flux-system
spec:
  targetNamespace: kube-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/kube-system/cilium/app
  prune: false # never should be deleted
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
# https://docs.cilium.io/en/latest/network/l2-announcements
apiVersion: cilium.io/v2alpha1
kind: CiliumL2AnnouncementPolicy
metadata:
  name: policy
spec:
  loadBalancerIPs: true
  # NOTE: This might need to be set if you have more than one active NIC on your nodes
  # interfaces:
  #   - ^eno[0-9]+
  nodeSelector:
    matchLabels:
      kubernetes.io/os: linux
---
apiVersion: cilium.io/v2alpha1
kind: CiliumLoadBalancerIPPool
metadata:
  name: pool
spec:
  cidrs:
    - cidr: "${NODE_CIDR}"
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./cilium-l2.yaml
  - ./helmvalues.yaml
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: cilium
spec:
  interval: 30m
  chart:
    spec:
      chart: cilium
      version: 1.14.5
      sourceRef:
        kind: HelmRepository
        name: cilium
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  valuesFrom:
    - name: cilium-values
      kind: ConfigMap
      valuesKey: values.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cilium-values
data:
  values.yaml: |
    autoDirectNodeRoutes: true
    bpf:
      masquerade: true
    bgp:
      enabled: false
    cluster:
      name: home-cluster
      id: 1
    containerRuntime:
      integration: containerd
      socketPath: /var/run/k3s/containerd/containerd.sock
    endpointRoutes:
      enabled: true
    hubble:
      enabled: true
      metrics:
        enabled:
          - dns:query
          - drop
          - tcp
          - flow
          - port-distribution
          - icmp
          - http
        serviceMonitor:
          enabled: true
        dashboards:
          enabled: true
          annotations:
            grafana_folder: Cilium
      relay:
        enabled: true
        rollOutPods: true
        prometheus:
          serviceMonitor:
            enabled: true
      ui:
        enabled: true
        rollOutPods: true
        ingress:
          enabled: true
          className: internal
          annotations:
            hajimari.io/icon: simple-icons:cilium
          hosts:
            - "hubble.${SECRET_DOMAIN}"
          tls:
            - hosts:
                - "hubble.${SECRET_DOMAIN}"
    ipam:
      mode: kubernetes
    ipv4NativeRoutingCIDR: "${CLUSTER_CIDR}"
    k8sServiceHost: "${KUBE_VIP_ADDR}"
    k8sServicePort: 6443
    kubeProxyReplacement: true
    kubeProxyReplacementHealthzBindAddr: 0.0.0.0:10256
    l2announcements:
      enabled: true
      # https://github.com/cilium/cilium/issues/26586
      leaseDuration: 120s
      leaseRenewDeadline: 60s
      leaseRetryPeriod: 1s
    loadBalancer:
      algorithm: maglev
      mode: dsr
    localRedirectPolicy: true
    operator:
      replicas: 1
      rollOutPods: true
      prometheus:
        enabled: true
        serviceMonitor:
          enabled: true
      dashboards:
        enabled: true
        annotations:
          grafana_folder: Cilium
    prometheus:
      enabled: true
      serviceMonitor:
        enabled: true
        trustCRDsExist: true
    dashboards:
      enabled: true
      annotations:
        grafana_folder: Cilium
    rollOutCiliumPods: true
    securityContext:
      privileged: true
    tunnel: disabled
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app snapshot-controller
  namespace: flux-system
spec:
  targetNamespace: kube-system
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/kube-system/snapshot-controller/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: snapshot-controller
spec:
  interval: 30m
  chart:
    spec:
      chart: snapshot-controller
      version: 2.0.4
      sourceRef:
        kind: HelmRepository
        name: piraeus
        namespace: flux-system
  maxHistory: 2
  install:
    crds: CreateReplace
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    crds: CreateReplace
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    controller:
      serviceMonitor:
        create: true
    webhook:
      enabled: false
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  # Pre Flux-Kustomizations
  - ./namespace.yaml
  # Flux-Kustomizations
  - ./volsync/ks.yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: volsync
  labels:
    kustomize.toolkit.fluxcd.io/prune: disabled
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app volsync
  namespace: flux-system
spec:
  targetNamespace: volsync
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/volsync/volsync/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmrelease.yaml
  - ./prometheusrule.yaml
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: volsync
spec:
  groups:
    - name: volsync.rules
      rules:
        - alert: VolSyncComponentAbsent
          annotations:
            summary: VolSync component has disappeared from Prometheus target discovery.
          expr: absent(up{job="volsync-metrics"})
          for: 15m
          labels:
            severity: critical
        - alert: VolSyncVolumeOutOfSync
          annotations:
            summary: "{{ $labels.obj_namespace }}/{{ $labels.obj_name }} volume is out of sync."
          expr: volsync_volume_out_of_sync == 1
          for: 15m
          labels:
            severity: critical
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: volsync
spec:
  interval: 30m
  chart:
    spec:
      chart: volsync
      version: 0.8.0
      sourceRef:
        kind: HelmRepository
        name: backube
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  dependsOn:
    - name: snapshot-controller
      namespace: kube-system
  values:
    manageCRDs: true
    image:
      # https://github.com/backube/volsync/issues/828
      repository: &image ghcr.io/onedr0p/volsync
      tag: &tag 0.8.0
    rclone:
      repository: *image
      tag: *tag
    restic:
      repository: *image
      tag: *tag
    metrics:
      disableAuth: true
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app kube-prometheus-stack
  namespace: flux-system
spec:
  targetNamespace: monitoring
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/monitoring/kube-prometheus-stack/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./helmvalues.yaml
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
spec:
  interval: 30m
  timeout: 15m
  chart:
    spec:
      chart: kube-prometheus-stack
      version: 55.5.1
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
  maxHistory: 2
  install:
    crds: CreateReplace
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    crds: CreateReplace
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  dependsOn:
    - name: local-path-provisioner
      namespace: kube-system
  valuesFrom:
    - name: kube-prometheus-stack-values
      kind: ConfigMap
      valuesKey: values.yaml
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-prometheus-stack-values
data:
  values.yaml: |
    crds:
      enabled: true
    cleanPrometheusOperatorObjectNames: true
    alertmanager:
      enabled: false
    kube-state-metrics:
      metricLabelsAllowlist:
        - "deployments=[*]"
        - "persistentvolumeclaims=[*]"
        - "pods=[*]"
      prometheus:
        monitor:
          enabled: true
          relabelings:
            - action: replace
              sourceLabels: ["__meta_kubernetes_pod_node_name"]
              regex: ^(.*)$
              replacement: $1
              targetLabel: kubernetes_node
    kubelet:
      enabled: true
      serviceMonitor:
        metricRelabelings:
          # Remove duplicate labels provided by k3s
          - action: keep
            sourceLabels: ["__name__"]
            regex: (apiserver_audit|apiserver_client|apiserver_delegated|apiserver_envelope|apiserver_storage|apiserver_webhooks|authentication_token|cadvisor_version|container_blkio|container_cpu|container_fs|container_last|container_memory|container_network|container_oom|container_processes|container|csi_operations|disabled_metric|get_token|go|hidden_metric|kubelet_certificate|kubelet_cgroup|kubelet_container|kubelet_containers|kubelet_cpu|kubelet_device|kubelet_graceful|kubelet_http|kubelet_lifecycle|kubelet_managed|kubelet_node|kubelet_pleg|kubelet_pod|kubelet_run|kubelet_running|kubelet_runtime|kubelet_server|kubelet_started|kubelet_volume|kubernetes_build|kubernetes_feature|machine_cpu|machine_memory|machine_nvm|machine_scrape|node_namespace|plugin_manager|prober_probe|process_cpu|process_max|process_open|process_resident|process_start|process_virtual|registered_metric|rest_client|scrape_duration|scrape_samples|scrape_series|storage_operation|volume_manager|volume_operation|workqueue)_(.+)
          - action: replace
            sourceLabels: ["node"]
            targetLabel: instance
          # Drop high cardinality labels
          - action: labeldrop
            regex: (uid)
          - action: labeldrop
            regex: (id|name)
          - action: drop
            sourceLabels: ["__name__"]
            regex: (rest_client_request_duration_seconds_bucket|rest_client_request_duration_seconds_sum|rest_client_request_duration_seconds_count)
    kubeApiServer:
      enabled: true
      serviceMonitor:
        metricRelabelings:
          # Remove duplicate labels provided by k3s
          - action: keep
            sourceLabels: ["__name__"]
            regex: (aggregator_openapi|aggregator_unavailable|apiextensions_openapi|apiserver_admission|apiserver_audit|apiserver_cache|apiserver_cel|apiserver_client|apiserver_crd|apiserver_current|apiserver_envelope|apiserver_flowcontrol|apiserver_init|apiserver_kube|apiserver_longrunning|apiserver_request|apiserver_requested|apiserver_response|apiserver_selfrequest|apiserver_storage|apiserver_terminated|apiserver_tls|apiserver_watch|apiserver_webhooks|authenticated_user|authentication|disabled_metric|etcd_bookmark|etcd_lease|etcd_request|field_validation|get_token|go|grpc_client|hidden_metric|kube_apiserver|kubernetes_build|kubernetes_feature|node_authorizer|pod_security|process_cpu|process_max|process_open|process_resident|process_start|process_virtual|registered_metric|rest_client|scrape_duration|scrape_samples|scrape_series|serviceaccount_legacy|serviceaccount_stale|serviceaccount_valid|watch_cache|workqueue)_(.+)
          # Drop high cardinality labels
          - action: drop
            sourceLabels: ["__name__"]
            regex: (apiserver|etcd|rest_client)_request(|_sli|_slo)_duration_seconds_bucket
          - action: drop
            sourceLabels: ["__name__"]
            regex: (apiserver_response_sizes_bucket|apiserver_watch_events_sizes_bucket)
    kubeControllerManager:
      enabled: true
      endpoints:
        - 192.168.31.50
        - 192.168.31.51
        - 192.168.31.52
      serviceMonitor:
        metricRelabelings:
          # Remove duplicate labels provided by k3s
          - action: keep
            sourceLabels: ["__name__"]
            regex: "(apiserver_audit|apiserver_client|apiserver_delegated|apiserver_envelope|apiserver_storage|apiserver_webhooks|attachdetach_controller|authenticated_user|authentication|cronjob_controller|disabled_metric|endpoint_slice|ephemeral_volume|garbagecollector_controller|get_token|go|hidden_metric|job_controller|kubernetes_build|kubernetes_feature|leader_election|node_collector|node_ipam|process_cpu|process_max|process_open|process_resident|process_start|process_virtual|pv_collector|registered_metric|replicaset_controller|rest_client|retroactive_storageclass|root_ca|running_managed|scrape_duration|scrape_samples|scrape_series|service_controller|storage_count|storage_operation|ttl_after|volume_operation|workqueue)_(.+)"
    kubeEtcd:
      enabled: true
      endpoints:
        - 192.168.31.50
        - 192.168.31.51
        - 192.168.31.52
    kubeScheduler:
      enabled: true
      endpoints:
        - 192.168.31.50
        - 192.168.31.51
        - 192.168.31.52
      serviceMonitor:
        metricRelabelings:
          # Remove duplicate labels provided by k3s
          - action: keep
            sourceLabels: ["__name__"]
            regex: "(apiserver_audit|apiserver_client|apiserver_delegated|apiserver_envelope|apiserver_storage|apiserver_webhooks|authenticated_user|authentication|disabled_metric|go|hidden_metric|kubernetes_build|kubernetes_feature|leader_election|process_cpu|process_max|process_open|process_resident|process_start|process_virtual|registered_metric|rest_client|scheduler|scrape_duration|scrape_samples|scrape_series|workqueue)_(.+)"
    kubeProxy:
      enabled: false # Disabled due to eBPF
    prometheus:
      ingress:
        enabled: true
        ingressClassName: internal
        annotations:
          hajimari.io/appName: Prometheus
          hajimari.io/icon: simple-icons:prometheus
        pathType: Prefix
        hosts:
          - "prometheus.${SECRET_DOMAIN}"
        tls:
          - hosts:
              - "prometheus.${SECRET_DOMAIN}"
      prometheusSpec:
        ruleSelectorNilUsesHelmValues: false
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelectorNilUsesHelmValues: false
        probeSelectorNilUsesHelmValues: false
        scrapeConfigSelectorNilUsesHelmValues: false
        enableAdminAPI: true
        walCompression: true
        retentionSize: 8GB
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: local-hostpath
              resources:
                requests:
                  storage: 10Gi
    grafana:
      enabled: false
      forceDeployDashboards: true
      sidecar:
        dashboards:
          multicluster:
            etcd:
              enabled: true
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app kubernetes-dashboard
  namespace: flux-system
spec:
  targetNamespace: monitoring
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  dependsOn:
    - name: cert-manager
    - name: metrics-server
  path: ./kubernetes/apps/monitoring/kubernetes-dashboard/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./rbac.yaml
  - ./helmrelease.yaml
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: kubernetes-dashboard
spec:
  interval: 30m
  chart:
    spec:
      chart: kubernetes-dashboard
      version: 6.0.8
      sourceRef:
        kind: HelmRepository
        name: kubernetes-dashboard
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    extraArgs:
      - --enable-insecure-login
      - --enable-skip-login
      - --disable-settings-authorizer
    ingress:
      enabled: true
      className: internal
      annotations:
        hajimari.io/icon: mdi:kubernetes
      hosts:
        - &host "kubernetes.${SECRET_DOMAIN}"
      tls:
        - hosts:
            - *host
    metricsScraper:
      enabled: true
# For dashboard sign in token:
# kubectl -n monitoring get secret kubernetes-dashboard -o jsonpath='{.data.token}' | base64 -d
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kubernetes-dashboard
  labels:
    app.kubernetes.io/managed-by: Helm
  annotations:
    meta.helm.sh/release-name: kubernetes-dashboard
    meta.helm.sh/release-namespace: monitoring
secrets:
  - name: kubernetes-dashboard
---
apiVersion: v1
kind: Secret
type: kubernetes.io/service-account-token
metadata:
  name: kubernetes-dashboard
  labels:
    app.kubernetes.io/managed-by: Helm
  annotations:
    meta.helm.sh/release-name: kubernetes-dashboard
    meta.helm.sh/release-namespace: monitoring
    kubernetes.io/service-account.name: kubernetes-dashboard
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: system:kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: kubernetes-dashboard
    namespace: monitoring
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./namespace.yaml
  - ./grafana/ks.yaml
  - ./kube-prometheus-stack/ks.yaml
  - ./kubernetes-dashboard/ks.yaml
---
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: &app grafana
  namespace: flux-system
spec:
  targetNamespace: monitoring
  commonMetadata:
    labels:
      app.kubernetes.io/name: *app
  path: ./kubernetes/apps/monitoring/grafana/app
  prune: true
  sourceRef:
    kind: GitRepository
    name: home-kubernetes
  wait: false
  interval: 30m
  retryInterval: 1m
  timeout: 5m
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - ./secret.sops.yaml
  - ./helmrelease.yaml
apiVersion: v1
kind: Secret
metadata:
    name: grafana-admin-secret
stringData:
    admin-password: ENC[AES256_GCM,data:ALfWX/qskg==,iv:jXAE35TK4DmbwGzJujILCZwfZY+3sQKBgWlFWlRbEtg=,tag:ZChg+XpGtAo1KjIqSQkHeA==,type:str]
    admin-user: ENC[AES256_GCM,data:F9uiv7o=,iv:gg9J/Izcluw+ikaICpZWpid30Lz6WKl4FlS8KMJInhM=,tag:n0Y9A7FEnvpc4i+UOYauOQ==,type:str]
sops:
    kms: []
    gcp_kms: []
    azure_kv: []
    hc_vault: []
    age:
        - recipient: age1nw624gkjpl0sattullahnekdswjcvsgarf8gwwyf9jdqc0zm9enqyp2pf6
          enc: |
            -----BEGIN AGE ENCRYPTED FILE-----
            YWdlLWVuY3J5cHRpb24ub3JnL3YxCi0+IFgyNTUxOSB2STJiVjA0dEc3M1FyM3Zp
            TG1BYmdESUI0SEpNc2dvcWE4a2lQT3QvcjNjCklOTXF0ME01bTFxYkk3TEtSaU9H
            RDZ3cENzRUFuVFBRSXJ0MmRqYjBxYW8KLS0tIFNNSnkwUXpzZkhBUy80ZTJ4aTdO
            eFFUUE40cFhHLzc3OXphNmFpdW9iMXcKQVfh9++jicoKK0x7TyK/dpumP+u2IAW0
            Jn8fQQ8Ac87oiqEiGRhP5b7DGICVO9JMyO6I/iFKXB5e4nI9O9vFWg==
            -----END AGE ENCRYPTED FILE-----
    lastmodified: "2023-12-29T11:28:45Z"
    mac: ENC[AES256_GCM,data:6N6DWw79PDsr7f2Xk+yYd1ljJpqTnDk9lIcWRz8OVMvqSK7KNGsUNEfly3rN/70oNjdHodqQoJ0CKsam3is7jl5Jb8nIi4EIAu2lDQLz9Wj+LLByYhPgMPWXpX83tSZsuvX+FyiJDGcerezBJge5na8p6U3e04/EdI9Cs6t5R5s=,iv:/8bxRBCt7xLEHGJpk+zE6ANDW075SnoIOP12T02oaIU=,tag:5pMlFMm3V/dZTojbVpMCaA==,type:str]
    pgp: []
    encrypted_regex: ^(data|stringData)$
    version: 3.8.1
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: grafana
spec:
  interval: 30m
  chart:
    spec:
      chart: grafana
      version: 7.0.19
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  dependsOn:
    - name: local-path-provisioner
      namespace: kube-system
  values:
    deploymentStrategy:
      type: Recreate
    admin:
      existingSecret: grafana-admin-secret
    env:
      GF_EXPLORE_ENABLED: true
      GF_SERVER_ROOT_URL: "https://grafana.${SECRET_DOMAIN}"
    grafana.ini:
      analytics:
        check_for_updates: false
        check_for_plugin_updates: false
        reporting_enabled: false
    dashboardProviders:
      dashboardproviders.yaml:
        apiVersion: 1
        providers:
          - name: default
            orgId: 1
            folder: ""
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/default
          - name: flux
            orgId: 1
            folder: Flux
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/flux
          - name: kubernetes
            orgId: 1
            folder: Kubernetes
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/kubernetes
          - name: nginx
            orgId: 1
            folder: Nginx
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/nginx
    datasources:
      datasources.yaml:
        apiVersion: 1
        deleteDatasources:
          - { name: Prometheus, orgId: 1 }
        datasources:
          - name: Prometheus
            type: prometheus
            uid: prometheus
            access: proxy
            url: http://kube-prometheus-stack-prometheus.monitoring.svc.cluster.local:9090
            jsonData:
              prometheusType: Prometheus
            isDefault: true
    dashboards:
      default:
        cloudflared:
          gnetId: 17457 # https://grafana.com/grafana/dashboards/17457?tab=revisions
          revision: 6
          datasource:
            - { name: DS_PROMETHEUS, value: Prometheus }
        external-dns:
          gnetId: 15038 # https://grafana.com/grafana/dashboards/15038?tab=revisions
          revision: 1
          datasource: Prometheus
        cert-manager:
          url: https://raw.githubusercontent.com/monitoring-mixins/website/master/assets/cert-manager/dashboards/cert-manager.json
          datasource: Prometheus
        node-exporter-full:
          gnetId: 1860 # https://grafana.com/grafana/dashboards/1860?tab=revisions
          revision: 31
          datasource: Prometheus
      flux:
        flux-cluster:
          url: https://raw.githubusercontent.com/fluxcd/flux2-monitoring-example/main/monitoring/configs/dashboards/cluster.json
          datasource: Prometheus
        flux-control-plane:
          url: https://raw.githubusercontent.com/fluxcd/flux2-monitoring-example/main/monitoring/configs/dashboards/control-plane.json
          datasource: Prometheus
      kubernetes:
        kubernetes-api-server:
          url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-system-api-server.json
          datasource: Prometheus
        kubernetes-coredns:
          url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-system-coredns.json
          datasource: Prometheus
        kubernetes-global:
          url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-global.json
          datasource: Prometheus
        kubernetes-namespaces:
          url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-namespaces.json
          datasource: Prometheus
        kubernetes-nodes:
          url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-nodes.json
          datasource: Prometheus
        kubernetes-pods:
          url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-pods.json
          datasource: Prometheus
      nginx:
        nginx:
          url: https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/grafana/dashboards/nginx.json
          datasource: Prometheus
        nginx-request-handling-performance:
          url: https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/grafana/dashboards/request-handling-performance.json
          datasource: Prometheus
    sidecar:
      dashboards:
        enabled: true
        searchNamespace: ALL
        labelValue: ""
        label: grafana_dashboard
        folderAnnotation: grafana_folder
        provider:
          disableDelete: true
          foldersFromFilesStructure: true
      datasources:
        enabled: true
        searchNamespace: ALL
        labelValue: ""
    serviceMonitor:
      enabled: true
    ingress:
      enabled: true
      ingressClassName: internal
      annotations:
        hajimari.io/icon: simple-icons:grafana
      hosts:
        - &host "grafana.${SECRET_DOMAIN}"
      tls:
        - hosts:
            - *host
    persistence:
      enabled: true
      storageClassName: local-hostpath
    testFramework:
      enabled: false
---
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    kustomize.toolkit.fluxcd.io/prune: disabled
